{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  0.3485\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  0.1107\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      " -0.0418\n",
      "\n",
      "(0 ,3 ,.,.) = \n",
      "  0.1335\n",
      "\n",
      "(0 ,4 ,.,.) = \n",
      "  0.3574\n",
      "[torch.FloatTensor of size 1x5x1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.init as ini\n",
    "import multiprocessing\n",
    "from multiprocessing import Queue\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "class InputCasNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InputCasNet, self).__init__()\n",
    "        self.first_upper_layer1=nn.Sequential(\n",
    "            nn.Conv2d(4,64,7),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((4,4),stride = 1)\n",
    "        )\n",
    "        self.first_upper_layer2=nn.Sequential(\n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2),stride = 1)\n",
    "        )\n",
    "        self.first_under_layer1=nn.Sequential(\n",
    "            nn.Conv2d(4,160,13),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.first_final_layer=nn.Conv2d(224,5,21)\n",
    "        \n",
    "        self.second_upper_layer1=nn.Sequential(\n",
    "            nn.Conv2d(9,64,7),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((4,4),stride = 1)\n",
    "        )\n",
    "        self.second_upper_layer2=nn.Sequential(\n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2),stride = 1)\n",
    "        )\n",
    "        self.second_under_layer1=self.under_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(9,160,13),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.second_final_layer = nn.Conv2d(224,5,21)\n",
    "    \n",
    "    def forward(self, x1, x2):\n",
    "        upper_x=self.first_upper_layer2(self.first_upper_layer1(x1))\n",
    "        under_x=self.first_under_layer1(x1)\n",
    "        x1=torch.cat((upper_x, under_x), 1)\n",
    "        x1=self.first_final_layer(x1)\n",
    "        x2=torch.cat((x1, x2), 1)\n",
    "        upper_x=self.second_upper_layer2(self.second_upper_layer1(x2))\n",
    "        under_x=self.second_under_layer1(x2)\n",
    "        x2=torch.cat((upper_x, under_x), 1)\n",
    "        x2=self.second_final_layer(x2)\n",
    "        return x2\n",
    "\n",
    "cas_net=InputCasNet()\n",
    "x1 = Variable(torch.randn(1,4,65,65), requires_grad = True)\n",
    "x2 = Variable(torch.randn(1,4,33,33), requires_grad = True)\n",
    "y_pred = cas_net.forward(x1, x2)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase 1 data preparation process completed.\n",
      "phase 2 data preparation process completed.\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "#get the training set for phase 1\n",
    "f=open(\"/home/yiqin/training-65x65-balanced.txt\", \"r\")\n",
    "content=f.readlines()\n",
    "data=[]\n",
    "data_train_phase1=[]\n",
    "i=0\n",
    "from random import shuffle\n",
    "shuffle(content)\n",
    "for line in content:\n",
    "    no_n_line=line[0:len(line)-1]\n",
    "    item=no_n_line.split(\" \")\n",
    "    data.append([])\n",
    "    data[i].append(item[0])\n",
    "    data[i].append(int(item[1]))\n",
    "    data[i].append(int(item[2]))\n",
    "    data[i].append(int(item[3]))\n",
    "    data[i].append(int(item[4]))\n",
    "    data_train_phase1.append(data[i])\n",
    "    i += 1\n",
    "f.close()\n",
    "print (\"phase 1 data preparation process completed.\")\n",
    "\n",
    "#get the training set for phase 2 and the validation set\n",
    "data_val=[]\n",
    "f_in=open(\"/home/yiqin/training-65x65-unbalanced.txt\", \"r\")\n",
    "content=f_in.readlines()\n",
    "data=[]\n",
    "data_val=[]\n",
    "data_train_phase2=[]\n",
    "i=0\n",
    "shuffle(content)\n",
    "for line in content:\n",
    "    no_n_line=line[0:len(line)-1]\n",
    "    item=no_n_line.split(\" \")\n",
    "    data.append([])\n",
    "    data[i].append(item[0])\n",
    "    data[i].append(int(item[1]))\n",
    "    data[i].append(int(item[2]))\n",
    "    data[i].append(int(item[3]))\n",
    "    data[i].append(int(item[4]))\n",
    "    if i%300000==0:\n",
    "        data_val.append(data[i])\n",
    "    else:\n",
    "        data_train_phase2.append(data[i])\n",
    "    i += 1\n",
    "f_in.close()\n",
    "print (\"phase 2 data preparation process completed.\")\n",
    "\n",
    "print(len(data_val))\n",
    "\n",
    "import h5py\n",
    "f = h5py.File('/home/yiqin/train.h5','r')\n",
    "f.swmr_code=True\n",
    "print(f[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_val(batch_mask):\n",
    "    X1_val=[]\n",
    "    X2_val=[]\n",
    "    y_val=[]\n",
    "    for i in range(len(batch_mask)):\n",
    "        case, x, y, z, l = data_val[batch_mask[i]]\n",
    "        case1 = case[:2]\n",
    "        case2 = case[3:]\n",
    "        content=f[case1][case2]\n",
    "        X2_val.append(content[:, x-16:x+17, y-16:y+17, z])\n",
    "        X1_val.append(content[:, x-32:x+33, y-32:y+33, z])\n",
    "        y_val.append(l)\n",
    "    X1_val = torch.from_numpy(np.array(X1_val))\n",
    "    X2_val = torch.from_numpy(np.array(X2_val))\n",
    "    y_val = torch.from_numpy(np.array(y_val))\n",
    "    return X1_val, X2_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def Process1(index, batch_size, nprocs=4):\n",
    "    def worker(index, batch_size, out_q):\n",
    "        if start>=len(data_train_phase1):\n",
    "            return\n",
    "        end=start+batch_size\n",
    "        if end>=len(data_train_phase1):\n",
    "            end=len(data_train_phase1)\n",
    "        X1_batch = []\n",
    "        X2_batch = []\n",
    "        y_batch = []\n",
    "        for index in range(start, end):\n",
    "            case, x, y, z, l = data_train_phase1[index]\n",
    "            case1 = case[:2]\n",
    "            case2 = case[3:]\n",
    "            X1_batch.append(f[case1][case2][:, x-32:x+33, y-32:y+33, z])\n",
    "            X2_batch.append(f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "            y_batch.append(l)\n",
    "        X1_batch = np.array(X1_batch)\n",
    "        X2_batch = np.array(X2_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "        out_q.put((X1_batch, X2_batch, y_batch))\n",
    "    \n",
    "    out_q=Queue()\n",
    "    procs=[]\n",
    "    batch_len=batch_size//nprocs\n",
    "    start=(index*batch_size)%len(data_train_phase1)\n",
    "    for i in range(nprocs):\n",
    "        start_index=start+i*batch_len\n",
    "        p = multiprocessing.Process(\n",
    "                target=worker,\n",
    "                args=(start_index, batch_len, out_q))\n",
    "        procs.append(p)\n",
    "        p.start()\n",
    "    X1_list=[]\n",
    "    X2_list=[]\n",
    "    y_list=[]\n",
    "    for i in range(nprocs):\n",
    "        X1_frac, X2_frac, y_frac=out_q.get()\n",
    "        X1_list.append(torch.from_numpy(X1_frac))\n",
    "        X2_list.append(torch.from_numpy(X2_frac))\n",
    "        y_list.append(torch.from_numpy(y_frac))\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "    X1_batch=torch.cat(X1_list)\n",
    "    X2_batch=torch.cat(X2_list)\n",
    "    y_batch=torch.cat(y_list)\n",
    "    return X1_batch, X2_batch, y_batch\n",
    "\n",
    "def Process2(index, batch_size, nprocs=4):\n",
    "    def worker(index, batch_size, out_q):\n",
    "        if start>=len(data_train_phase2):\n",
    "            return\n",
    "        end=start+batch_size\n",
    "        if end>=len(data_train_phase2):\n",
    "            end=len(data_train_phase2)\n",
    "        X1_batch = []\n",
    "        X2_batch = []\n",
    "        y_batch = []\n",
    "        for index in range(start, end):\n",
    "            case, x, y, z, l = data_train_phase2[index]\n",
    "            case1 = case[:2]\n",
    "            case2 = case[3:]\n",
    "            X1_batch.append(f[case1][case2][:, x-32:x+33, y-32:y+33, z])\n",
    "            X2_batch.append(f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "            y_batch.append(l)\n",
    "        X1_batch = np.array(X1_batch)\n",
    "        X2_batch = np.array(X2_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "        out_q.put((X1_batch, X2_batch, y_batch))\n",
    "    \n",
    "    out_q=Queue()\n",
    "    procs=[]\n",
    "    batch_len=batch_size//nprocs\n",
    "    start=(index*batch_size)%len(data_train_phase2)\n",
    "    for i in range(nprocs):\n",
    "        start_index=start+i*batch_len\n",
    "        p = multiprocessing.Process(\n",
    "                target=worker,\n",
    "                args=(start_index, batch_len, out_q))\n",
    "        procs.append(p)\n",
    "        p.start()\n",
    "    X1_list=[]\n",
    "    X2_list=[]\n",
    "    y_list=[]\n",
    "    for i in range(nprocs):\n",
    "        X1_frac, X2_frac, y_frac=out_q.get()\n",
    "        X1_list.append(torch.from_numpy(X1_frac))\n",
    "        X2_list.append(torch.from_numpy(X2_frac))\n",
    "        y_list.append(torch.from_numpy(y_frac))\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "    X1_batch=torch.cat(X1_list)\n",
    "    X2_batch=torch.cat(X2_list)\n",
    "    y_batch=torch.cat(y_list)\n",
    "    return X1_batch, X2_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas_net=InputCasNet()\n",
    "cas_net.cuda(2)\n",
    "for param in cas_net.parameters():\n",
    "    if len(param.size())==4:\n",
    "        ini.uniform(param, a=-5e-3, b=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "l1_reg = 5e-3\n",
    "optimizer = torch.optim.SGD(cas_net.parameters(), lr=learning_rate, momentum = 0.9, weight_decay = 5e-8)\n",
    "num_train=len(data_train_phase1)\n",
    "num_val=len(data_val)\n",
    "val_size=num_val\n",
    "\n",
    "#create validation set\n",
    "val_mask=np.random.choice(num_val, val_size)\n",
    "X1_val, X2_val, y_val=create_val(val_mask)\n",
    "X1_val, X2_val= Variable(X1_val.cuda(2), requires_grad=False), Variable(X2_val.cuda(2), requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yiqin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 249, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/yiqin/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-8-119895c419cf>\", line 16, in worker\n",
      "    X1_batch.append(f[case1][case2][:, x-32:x+33, y-32:y+33, z])\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496889914775/work/h5py/_objects.c:2846)\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496889914775/work/h5py/_objects.c:2804)\n",
      "  File \"/home/yiqin/anaconda3/lib/python3.6/site-packages/h5py/_hl/group.py\", line 169, in __getitem__\n",
      "    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496889914775/work/h5py/_objects.c:2846)\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496889914775/work/h5py/_objects.c:2804)\n",
      "KeyError: 'Unable to open object (Bad object header version number)'\n",
      "  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open (/home/ilan/minonda/conda-bld/h5py_1496889914775/work/h5py/h5o.c:3740)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1abb5d5bce5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mX1_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mX2_batch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mX1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProcess1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mX1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcas_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-119895c419cf>\u001b[0m in \u001b[0;36mProcess1\u001b[0;34m(index, batch_size, nprocs)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0my_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnprocs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mX1_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX2_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_frac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mX1_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_frac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mX2_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2_frac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "num_epoch = 2\n",
    "batch_size = 128\n",
    "step_size = num_train // batch_size+1\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "num_times=num_epoch*step_size\n",
    "\n",
    "prev_time = time.clock()\n",
    "for i in range(1):\n",
    "    for j in range(1001):\n",
    "        index=i*step_size+j\n",
    "        X1_batch=None\n",
    "        X2_batch=None\n",
    "        X1_batch, X2_batch, y_batch = Process1(index, batch_size)\n",
    "        X1_batch, X2_batch, y_batch = Variable(X1_batch.cuda(2)), Variable(X2_batch.cuda(2)), Variable(y_batch.cuda(2), requires_grad = False)\n",
    "        y_pred = cas_net.forward(X1_batch, X2_batch)\n",
    "        y_pred = y_pred.view(-1,5)\n",
    "        loss = F.cross_entropy(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if index % 100 == 0:\n",
    "            print (\"\")\n",
    "            print (str(index)+' time used %.3f' % (time.clock()-prev_time))\n",
    "            print ('phase 1: '+str(float(index)/num_times*100)+\"% completed\")\n",
    "            print (loss)\n",
    "            y_val_pred=cas_net.forward(X1_val, X2_val)\n",
    "            y_val_pred=y_val_pred.view(-1,5)\n",
    "            useless, predicted=torch.max(y_val_pred.data, 1)\n",
    "            correct = (predicted == y_val.cuda(2)).sum()\n",
    "            print('Validation accuracy:', float(correct)/num_val)\n",
    "    scheduler.step()\n",
    "\n",
    "print (\"phase1: successfully trained!\")\n",
    "#torch.save(cas_net.state_dict(), \"phase1_input_cas_net.txt\")\n",
    "print (\"phase1: successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "case, x, y, z, l = data_train_phase1[2]\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
