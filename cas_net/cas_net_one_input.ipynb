{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      "  0.1330\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      " -0.2205\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "  0.4249\n",
      "\n",
      "(0 ,3 ,.,.) = \n",
      "  0.1712\n",
      "\n",
      "(0 ,4 ,.,.) = \n",
      "  0.0584\n",
      "[torch.FloatTensor of size 1x5x1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.init as ini\n",
    "import multiprocessing\n",
    "from multiprocessing import Queue\n",
    "import random\n",
    "from random import shuffle\n",
    "import pickle\n",
    "\n",
    "class InputCasNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InputCasNet, self).__init__()\n",
    "        self.first_upper_layer1=nn.Sequential(\n",
    "            nn.Conv2d(4,64,7),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((4,4),stride = 1)\n",
    "        )\n",
    "        self.first_upper_layer2=nn.Sequential(\n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2),stride = 1)\n",
    "        )\n",
    "        self.first_under_layer1=nn.Sequential(\n",
    "            nn.Conv2d(4,160,13),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.first_final_layer=nn.Conv2d(224,5,21)\n",
    "        \n",
    "        self.second_upper_layer1=nn.Sequential(\n",
    "            nn.Conv2d(9,64,7),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((4,4),stride = 1)\n",
    "        )\n",
    "        self.second_upper_layer2=nn.Sequential(\n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2),stride = 1)\n",
    "        )\n",
    "        self.second_under_layer1=self.under_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(9,160,13),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.second_final_layer = nn.Conv2d(224,5,21)\n",
    "    \n",
    "    def forward(self, x1):\n",
    "        upper_x=self.first_upper_layer2(self.first_upper_layer1(x1))\n",
    "        under_x=self.first_under_layer1(x1)\n",
    "        x=torch.cat((upper_x, under_x), 1)\n",
    "        x=self.first_final_layer(x)\n",
    "        x2=x1[:, :, 16:48+1, 16:48+1]*1.0\n",
    "        x2=torch.cat((x, x2), 1)\n",
    "        upper_x2=self.second_upper_layer2(self.second_upper_layer1(x2))\n",
    "        under_x2=self.second_under_layer1(x2)\n",
    "        x3=torch.cat((upper_x2, under_x2), 1)\n",
    "        x3=self.second_final_layer(x3)\n",
    "        return x3\n",
    "\n",
    "cas_net=InputCasNet()\n",
    "x1 = Variable(torch.randn(1,4,65,65), requires_grad = True)\n",
    "y_pred = cas_net.forward(x1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase 1 data preparation process completed.\n",
      "phase 2 data preparation process completed.\n",
      "8071683\n",
      "21254359\n",
      "1186058\n"
     ]
    }
   ],
   "source": [
    "f = h5py.File('/home/yiqin/train.h5','r')\n",
    "\n",
    "#get the training set for phase 1\n",
    "f_in=open(\"/home/yiqin/training-65x65-balanced.txt\", \"r\")\n",
    "content=f_in.readlines()\n",
    "data_train_phase1=[]\n",
    "data_val=[]\n",
    "for line in content:\n",
    "    no_n_line=line[0:len(line)-1]\n",
    "    item=no_n_line.split(\" \")\n",
    "    if item[0]!=\"HG/0001\":\n",
    "        data_train_phase1.append([item[0], item[1], item[2], item[3], item[4]])\n",
    "    else:\n",
    "        data_val.append([item[0], item[1], item[2], item[3], item[4]])\n",
    "f_in.close()\n",
    "print (\"phase 1 data preparation process completed.\")\n",
    "\n",
    "#get the training set for phase 2 and the validation set\n",
    "f_in=open(\"/home/yiqin/training-65x65-unbalanced.txt\", \"r\")\n",
    "content=f_in.readlines()\n",
    "data_train_phase2=[]\n",
    "for line in content:\n",
    "    no_n_line=line[0:len(line)-1]\n",
    "    item=no_n_line.split(\" \")\n",
    "    if item[0]!=\"HG/0001\":\n",
    "        data_train_phase2.append([item[0], item[1], item[2], item[3], item[4]])\n",
    "    else:\n",
    "        data_val.append([item[0], item[1], item[2], item[3], item[4]])\n",
    "f_in.close()\n",
    "print (\"phase 2 data preparation process completed.\")\n",
    "\n",
    "print(len(data_train_phase1))\n",
    "print(len(data_train_phase2))\n",
    "print(len(data_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_val_batch_phase1(step = 6000, key = 299):\n",
    "    val_x1 = []\n",
    "    val_label = []\n",
    "    batch_size = len(data_val) // step\n",
    "    for i in range(batch_size):\n",
    "        case,x,y,z,l = data_val.pop(i * step + key - i)\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        x1 = f[case1][case2][:, x-32:x+32+1, y-32:y+32+1, z]\n",
    "        val_x1.append(x1)\n",
    "        val_label.append(l)\n",
    "    val_x1 = torch.from_numpy(np.array(val_x1))\n",
    "    val_label = torch.from_numpy(np.array(val_label))\n",
    "    return val_x1, val_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1185861\n",
      "197\n"
     ]
    }
   ],
   "source": [
    "#create valid_set\n",
    "val_len = len(data_val)\n",
    "\n",
    "val_x1, val_y = create_val_batch_phase1()\n",
    "val_y = val_y.view(-1)\n",
    "val_x1=Variable(val_x1.cuda(2))\n",
    "print(len(data_val))\n",
    "print(len(val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set hyper_param\n",
    "learning_rate = 5e-4\n",
    "l1_reg = 5e-5\n",
    "optimizer = torch.optim.SGD(cas_net.parameters(), lr=learning_rate, momentum = 0.9, weight_decay = 5e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for param in cas_net.parameters():\n",
    "    if len(param.size())==4:\n",
    "        ini.uniform(param, a=-5e-4, b=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_batch(size, j):\n",
    "    train_x1 = []\n",
    "    train_label = []\n",
    "    for i in range(size):\n",
    "        case,x,y,z,l = data_train_phase1[j * size + i]\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        x1 = f[case1][case2][:, x-32:x+32+1, y-32:y+32+1, z]\n",
    "        train_x1.append(x1)\n",
    "        train_label.append(l)\n",
    "    train_x1 = torch.from_numpy(np.array(train_x1))\n",
    "    train_label = torch.from_numpy(np.array(train_label))\n",
    "    return train_x1, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315300\n"
     ]
    }
   ],
   "source": [
    "cas_net.cuda(2)\n",
    "prev_time = time.clock()\n",
    "num_epoch = 5\n",
    "batch_size = 128\n",
    "step_size = len(data_train_phase1) // batch_size\n",
    "num_times=num_epoch*step_size\n",
    "print(num_times)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  0.4975\n",
      " -0.4909\n",
      " -1.4639\n",
      "  0.4771\n",
      "  1.1673\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 2)]\n",
      "\n",
      "\n",
      "0 time used 58.487\n",
      "phase 1: 0.0% completed\n",
      "Variable containing:\n",
      " 1.1785\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "Validation accuracy: 0.6751269035532995\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.1986\n",
      " -1.1227\n",
      " -1.4498\n",
      "  1.1243\n",
      "  1.6237\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 2)]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.0156\n",
      " -1.8696\n",
      " -0.9071\n",
      "  1.0407\n",
      "  1.6728\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 2)]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-04 *\n",
      "  3.7853\n",
      " -6.8001\n",
      " -6.1409\n",
      "  5.3043\n",
      "  6.9126\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 2)]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  0.5434\n",
      " -0.7323\n",
      " -1.2097\n",
      "  0.5508\n",
      "  1.0324\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 2)]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  1.2157\n",
      " -0.7551\n",
      " -2.0034\n",
      "  1.2828\n",
      "  2.0369\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 2)]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  0.6370\n",
      " -1.5142\n",
      " -0.6723\n",
      "  0.8727\n",
      "  1.2412\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 2)]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  0.8978\n",
      " -0.8293\n",
      " -1.3901\n",
      "  0.9486\n",
      "  1.5520\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 2)]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  0.5934\n",
      " -1.2090\n",
      " -1.9885\n",
      "  1.3635\n",
      "  1.8004\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 2)]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  0.8738\n",
      " -1.9983\n",
      " -1.1818\n",
      "  1.1607\n",
      "  1.7113\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 2)]\n",
      "\n",
      "Variable containing:\n",
      "1.00000e-03 *\n",
      "  0.9743\n",
      " -1.0161\n",
      " -2.8403\n",
      "  1.7072\n",
      "  2.7846\n",
      "[torch.cuda.FloatTensor of size 5 (GPU 2)]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f33990b93a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_phase1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mtraining_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mx1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_x1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcas_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-89385163dcac>\u001b[0m in \u001b[0;36mcreate_batch\u001b[0;34m(size, j)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mcase1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcase2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mtrain_x1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496889914775/work/h5py/_objects.c:2846)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/home/ilan/minonda/conda-bld/h5py_1496889914775/work/h5py/_objects.c:2804)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(num_epoch):\n",
    "    random.shuffle(data_train_phase1)\n",
    "    for j in range(201):\n",
    "        training_x1, training_label = create_batch(batch_size, j)\n",
    "        x1_train, y_train = Variable(training_x1.cuda(2)), Variable(training_label.cuda(2), requires_grad=False)\n",
    "        y_pred = cas_net.forward(x1_train)\n",
    "        y_pred = y_pred.view(-1,5)\n",
    "        loss = F.cross_entropy(y_pred, y_train)#cross entropy loss\n",
    "\n",
    "#        l1_crit = nn.L1Loss(size_average = False)#L1 loss\n",
    "#        reg_loss = 0\n",
    "#        for param in net.parameters():\n",
    "#            reg_loss += l1_crit(param)\n",
    "#        loss+= l1_reg * reg_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        print(cas_net.first_final_layer.bias.grad)\n",
    "        optimizer.step()\n",
    "        #check accuracy\n",
    "        index=i*step_size+j\n",
    "        if index % 2000 == 0:\n",
    "            print (\"\")\n",
    "            print (str(index)+' time used %.3f' % (time.clock()-prev_time))\n",
    "            print ('phase 1: '+str(float(index)/num_times*100)+\"% completed\")\n",
    "            print (loss)\n",
    "            y_val_pred=cas_net.forward(val_x1)\n",
    "            y_val_pred=y_val_pred.view(-1,5)\n",
    "            useless, predicted=torch.max(y_val_pred.data, 1)\n",
    "            correct = (predicted == val_y.cuda(2)).sum()\n",
    "            print('Validation accuracy:', float(correct)/len(val_y))\n",
    "    scheduler.step()\n",
    "    print (\"phase1 epoch: \" + str(i)+\" successfully trained!\")\n",
    "    torch.save(cas_net.state_dict(), \"/home/yiqin/phase1_input_cas_net.txt\")\n",
    "    print (\"phase1 epoch: \" + str(i)+\" successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_batch2(size, j):\n",
    "    train_x1 = []\n",
    "    train_label = []\n",
    "    for i in range(size):\n",
    "        case,x,y,z,l = data_train_phase2[j * size + i]\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        x1 = f[case1][case2][:, x-32:x+32+1, y-32:y+32+1, z]\n",
    "        train_x1.append(x1)\n",
    "        train_label.append(l)\n",
    "    train_x1 = torch.from_numpy(np.array(train_x1))\n",
    "    train_label = torch.from_numpy(np.array(train_label))\n",
    "    return train_x1, train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas_net=InputCasNet()\n",
    "cas_net.load_state_dict(torch.load(\"/home/yiqin/phase1_input_cas_net.txt\"))\n",
    "cas_net.cuda(2)\n",
    "prev_time = time.clock()\n",
    "num_epoch = 2\n",
    "batch_size = 128\n",
    "step_size = len(data_train_phase2) // batch_size\n",
    "num_times=num_epoch*step_size\n",
    "print(num_times)\n",
    "learning_rate = 5e-5\n",
    "l1_reg = 5e-5\n",
    "optimizer = torch.optim.SGD(cas_net.second_final_layer.parameters(), lr=learning_rate, momentum = 0.9, weight_decay = 5e-7)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(num_epoch):\n",
    "    random.shuffle(data_train_phase2)\n",
    "    for j in range(step_size):\n",
    "        training_x1, training_label = create_batch2(batch_size, j)\n",
    "        x1_train, y_train = Variable(training_x1.cuda(2)), Variable(training_label.cuda(2), requires_grad=False)\n",
    "        y_pred = cas_net.forward(x1_train)\n",
    "        y_pred = y_pred.view(-1,5)\n",
    "        loss = F.cross_entropy(y_pred, y_train)#cross entropy loss\n",
    "\n",
    "#        l1_crit = nn.L1Loss(size_average = False)#L1 loss\n",
    "#        reg_loss = 0\n",
    "#        for param in net.parameters():\n",
    "#            reg_loss += l1_crit(param)\n",
    "#        loss+= l1_reg * reg_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #check accuracy\n",
    "        index=i*step_size+j\n",
    "        if index % 2000 == 0:\n",
    "            print (\"\")\n",
    "            print (str(index)+' time used %.3f' % (time.clock()-prev_time))\n",
    "            print ('phase 2: '+str(float(index)/num_times*100)+\"% completed\")\n",
    "            print (loss)\n",
    "            y_val_pred=cas_net.forward(val_x1)\n",
    "            y_val_pred=y_val_pred.view(-1,5)\n",
    "            useless, predicted=torch.max(y_val_pred.data, 1)\n",
    "            correct = (predicted == val_y.cuda(2)).sum()\n",
    "            print('Validation accuracy:', float(correct)/len(val_y))\n",
    "    scheduler.step()\n",
    "    print (\"phase2 epoch: \" + str(i)+\" successfully trained!\")\n",
    "    torch.save(cas_net.state_dict(), \"/home/yiqin/phase2_input_cas_net.txt\")\n",
    "    print (\"phase2 epoch: \" + str(i)+\" successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
