{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoPathConv (\n",
      "  (upper_layer1): Sequential (\n",
      "    (0): Conv2d(4, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(4, 4), stride=(1, 1), dilation=(1, 1))\n",
      "  )\n",
      "  (upper_layer2): Sequential (\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  )\n",
      "  (under_layer1): Sequential (\n",
      "    (0): Conv2d(4, 160, kernel_size=(13, 13), stride=(1, 1))\n",
      "    (1): ReLU ()\n",
      "  )\n",
      "  (final_layer): Conv2d(224, 5, kernel_size=(21, 21), stride=(1, 1))\n",
      ")\n",
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -0.2623\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      "  0.2611\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      " -0.5541\n",
      "\n",
      "(0 ,3 ,.,.) = \n",
      " -0.3231\n",
      "\n",
      "(0 ,4 ,.,.) = \n",
      " -0.0795\n",
      "[torch.FloatTensor of size 1x5x1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TwoPathConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoPathConv, self).__init__()\n",
    "        self.upper_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(4,64,7),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((4,4),stride = 1)\n",
    "        )\n",
    "        self.upper_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2),stride = 1)\n",
    "        )\n",
    "        self.under_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(4,160,13),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.final_layer = nn.Conv2d(224,5,21)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        upper_x = self.upper_layer2(self.upper_layer1(x))\n",
    "        under_x = self.under_layer1(x)\n",
    "        #upper_x = F.max_pool2d(F.relu(self.upper_conv1(x)), (4, 4),stride = 1)\n",
    "        #upper_x = F.max_pool2d(F.relu(self.upper_conv2(upper_x)), (2, 2), stride = 1)\n",
    "        #under_x = F.relu(self.under_conv1(x))\n",
    "        final_x = torch.cat((under_x, upper_x), 1)\n",
    "        out = self.final_layer(final_x)\n",
    "        return out\n",
    "        \n",
    "net = TwoPathConv()\n",
    "print(net)\n",
    "\n",
    "x = Variable(torch.randn(1,4,33,33), requires_grad = True)\n",
    "y_pred = net.forward(x)\n",
    "print(y_pred)\n",
    "#y_pred = y_pred.data.resize_(1,5)\n",
    "#y_pred = Variable(y_pred,requires_grad = True)\n",
    "#print(y_pred.size())\n",
    "#print(y_pred.view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase 1 data preparation process completed.\n",
      "phase 2 data preparation process completed.\n"
     ]
    }
   ],
   "source": [
    "#get the training set for phase 1\n",
    "f=open(\"trainval-balanced.txt\", \"r\")\n",
    "content=f.readlines()\n",
    "data=[]\n",
    "data_train_phase1=[]\n",
    "i=0\n",
    "from random import shuffle\n",
    "shuffle(content)\n",
    "for line in content:\n",
    "    no_n_line=line[0:len(line)-1]\n",
    "    item=no_n_line.split(\" \")\n",
    "    data.append([])\n",
    "    data[i].append(item[0])\n",
    "    data[i].append(int(item[1]))\n",
    "    data[i].append(int(item[2]))\n",
    "    data[i].append(int(item[3]))\n",
    "    data[i].append(int(item[4]))\n",
    "    data_train_phase1.append(data[i])\n",
    "    i += 1\n",
    "f.close()\n",
    "\n",
    "print (\"phase 1 data preparation process completed.\")\n",
    "\n",
    "#get the training set for phase 2 and the validation set\n",
    "data_val=[]\n",
    "f_in=open(\"trainval.txt\", \"r\")\n",
    "content=f_in.readlines()\n",
    "data=[]\n",
    "data_val=[]\n",
    "data_train_phase2=[]\n",
    "i=0\n",
    "shuffle(content)\n",
    "for line in content:\n",
    "    no_n_line=line[0:len(line)-1]\n",
    "    item=no_n_line.split(\" \")\n",
    "    data.append([])\n",
    "    data[i].append(item[0])\n",
    "    data[i].append(int(item[1]))\n",
    "    data[i].append(int(item[2]))\n",
    "    data[i].append(int(item[3]))\n",
    "    data[i].append(int(item[4]))\n",
    "    if i%30000==0:\n",
    "        data_val.append(data[i])\n",
    "    else:\n",
    "        data_train_phase2.append(data[i])\n",
    "    i += 1\n",
    "f_in.close()\n",
    "print (\"phase 2 data preparation process completed.\")\n",
    "\n",
    "\n",
    "import h5py\n",
    "f = h5py.File('training.h5','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24778697\n",
      "826\n",
      "8998296\n",
      "24777871\n"
     ]
    }
   ],
   "source": [
    "print (len(data))\n",
    "print (len(data_val))\n",
    "print (len(data_train_phase1))\n",
    "print (len(data_train_phase2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print (torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.init as ninit\n",
    "def init_net(net):\n",
    "    for param in net.parameters():\n",
    "        ninit.uniform(param.data, a=-5e-3, b=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_batch_phase1(start, batch_size):\n",
    "    X_batch= None\n",
    "    y_batch= None\n",
    "    if start>=len(data_train_phase1):\n",
    "        return X_batch, y_batch\n",
    "    end=start+batch_size\n",
    "    if end>=len(data_train_phase1):\n",
    "        end=len(data_train_phase1)\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    for index in range(start, end):\n",
    "        case, x, y, z, l = data_train_phase1[index]\n",
    "        case1 = case[:2]\n",
    "        case2 = case[3:]\n",
    "        X_batch.append(f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "        y_batch.append(l)\n",
    "    X_batch = torch.from_numpy(np.array(X_batch))\n",
    "    y_batch = torch.from_numpy(np.array(y_batch))\n",
    "    return X_batch, y_batch\n",
    "\n",
    "def create_batch_phase2(start, batch_size):\n",
    "    X_batch= None\n",
    "    y_batch= None\n",
    "    if start>=len(data_train_phase2):\n",
    "        return X_batch, y_batch\n",
    "    end=start+batch_size\n",
    "    if end>=len(data_train_phase2):\n",
    "        end=len(data_train_phase2)\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    for index in range(start, end):\n",
    "        case, x, y, z, l = data_train_phase2[index]\n",
    "        case1 = case[:2]\n",
    "        case2 = case[3:]\n",
    "        X_batch.append(f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "        y_batch.append(l)\n",
    "    X_batch = torch.from_numpy(np.array(X_batch))\n",
    "    y_batch = torch.from_numpy(np.array(y_batch))\n",
    "    return X_batch, y_batch\n",
    "\n",
    "def create_val(batch_mask):\n",
    "    X_val=[]\n",
    "    y_val=[]\n",
    "    for i in range(len(batch_mask)):\n",
    "        case, x, y, z, l = data_val[batch_mask[i]]\n",
    "        case1 = case[:2]\n",
    "        case2 = case[3:]\n",
    "        X_val.append(f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "        y_val.append(l)\n",
    "    X_val = torch.from_numpy(np.array(X_val))\n",
    "    y_val = torch.from_numpy(np.array(y_val))\n",
    "    return X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import threading\n",
    "from threading import Thread\n",
    "class DataThread(Thread):\n",
    "    def __init__(self,func,args,name=''):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.name=name\n",
    "        self.func=func\n",
    "        self.args=args\n",
    "    \n",
    "    def run(self):\n",
    "        index, batch_size=self.args\n",
    "        self.X_batch, self.y_batch=self.func(index, batch_size)\n",
    "\n",
    "class GetTrainDataPhase1():\n",
    "    def __init__(self, index, batch_size, thread_num=4):\n",
    "        self.threads=[]\n",
    "        batch_len=batch_size//thread_num\n",
    "        self.X_batch=[]\n",
    "        self.y_batch=[]\n",
    "        start=(index*batch_size)%len(data_train_phase1)\n",
    "        for i in range(thread_num):\n",
    "            start_index=start+i*batch_len\n",
    "            t=DataThread(create_batch_phase1, (start_index, batch_len))\n",
    "            self.threads.append(t)\n",
    "    \n",
    "    def run(self):\n",
    "        for i in range(len(self.threads)):\n",
    "            self.threads[i].start()\n",
    "        for i in range(len(self.threads)):\n",
    "            self.threads[i].join()\n",
    "            self.X_batch.append(self.threads[i].X_batch)\n",
    "            self.y_batch.append(self.threads[i].y_batch)\n",
    "        X_batch=torch.cat(self.X_batch)\n",
    "        y_batch=torch.cat(self.y_batch)\n",
    "        return X_batch, y_batch\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Queue\n",
    "\n",
    "def Process1(index, batch_size, nprocs=4):\n",
    "    def worker(index, batch_size, out_q):\n",
    "        if start>=len(data_train_phase1):\n",
    "            return\n",
    "        end=start+batch_size\n",
    "        if end>=len(data_train_phase1):\n",
    "            end=len(data_train_phase1)\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for index in range(start, end):\n",
    "            case, x, y, z, l = data_train_phase1[index]\n",
    "            case1 = case[:2]\n",
    "            case2 = case[3:]\n",
    "            X_batch.append(f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "            y_batch.append(l)\n",
    "        X_batch = np.array(X_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "        out_q.put((X_batch, y_batch))\n",
    "    \n",
    "    out_q=Queue()\n",
    "    procs=[]\n",
    "    batch_len=batch_size//nprocs\n",
    "    start=(index*batch_size)%len(data_train_phase1)\n",
    "    for i in range(nprocs):\n",
    "        start_index=start+i*batch_len\n",
    "        p = multiprocessing.Process(\n",
    "                target=worker,\n",
    "                args=(start_index, batch_len, out_q))\n",
    "        procs.append(p)\n",
    "        p.start()\n",
    "    X_list=[]\n",
    "    y_list=[]\n",
    "    for i in range(nprocs):\n",
    "        X_frac, y_frac=out_q.get()\n",
    "        X_list.append(torch.from_numpy(X_frac))\n",
    "        y_list.append(torch.from_numpy(y_frac))\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "    X_batch=torch.cat(X_list)\n",
    "    y_batch=torch.cat(y_list)\n",
    "    return X_batch, y_batch\n",
    "\n",
    "def Process2(index, batch_size, nprocs=4):\n",
    "    def worker(index, batch_size, out_q):\n",
    "        if start>=len(data_train_phase2):\n",
    "            return\n",
    "        end=start+batch_size\n",
    "        if end>=len(data_train_phase2):\n",
    "            end=len(data_train_phase2)\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for index in range(start, end):\n",
    "            case, x, y, z, l = data_train_phase2[index]\n",
    "            case1 = case[:2]\n",
    "            case2 = case[3:]\n",
    "            X_batch.append(f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "            y_batch.append(l)\n",
    "        X_batch = np.array(X_batch)\n",
    "        y_batch = np.array(y_batch)\n",
    "        out_q.put((X_batch, y_batch))\n",
    "    \n",
    "    out_q=Queue()\n",
    "    procs=[]\n",
    "    batch_len=batch_size//nprocs\n",
    "    start=(index*batch_size)%len(data_train_phase1)\n",
    "    for i in range(nprocs):\n",
    "        start_index=start+i*batch_len\n",
    "        p = multiprocessing.Process(\n",
    "                target=worker,\n",
    "                args=(start_index, batch_len, out_q))\n",
    "        procs.append(p)\n",
    "        p.start()\n",
    "    X_list=[]\n",
    "    y_list=[]\n",
    "    for i in range(nprocs):\n",
    "        X_frac, y_frac=out_q.get()\n",
    "        X_list.append(torch.from_numpy(X_frac))\n",
    "        y_list.append(torch.from_numpy(y_frac))\n",
    "    for p in procs:\n",
    "        p.join()\n",
    "    X_batch=torch.cat(X_list)\n",
    "    y_batch=torch.cat(y_list)\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35149\n",
      "TwoPathConv (\n",
      "  (upper_layer1): Sequential (\n",
      "    (0): Conv2d(4, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(4, 4), stride=(1, 1), dilation=(1, 1))\n",
      "  )\n",
      "  (upper_layer2): Sequential (\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  )\n",
      "  (under_layer1): Sequential (\n",
      "    (0): Conv2d(4, 160, kernel_size=(13, 13), stride=(1, 1))\n",
      "    (1): ReLU ()\n",
      "  )\n",
      "  (final_layer): Conv2d(224, 5, kernel_size=(21, 21), stride=(1, 1))\n",
      ")\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.41813700000000154\n",
      "\n",
      "time used 0.937\n",
      "0.0% completed\n",
      "Variable containing:\n",
      " 1.6081\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 0)]\n",
      "\n",
      "Validation accuracy: 0.17554479418886199\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.43669999999997344\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.4432909999999879\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.4394990000000121\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.5086779999999749\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.4450790000000211\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.4681600000000117\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.47484100000002627\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.470074000000011\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.44442500000002383\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.5005749999999694\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.4915579999999977\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.5134929999999827\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.4504440000000045\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.4410209999999779\n",
      "torch.Size([512, 4, 33, 33])\n",
      "batch_time: 0.4757809999999836\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "num_train=len(data_train_phase1)\n",
    "num_val=len(data_val)\n",
    "batch_size=512\n",
    "val_size=num_val\n",
    "num_epoch=2.0\n",
    "num_times=int(float(num_train)/batch_size*num_epoch)\n",
    "print (num_times)\n",
    "learning_rate = 5e-3\n",
    "reg=5e-5\n",
    "net = TwoPathConv()\n",
    "print(net)\n",
    "init_net(net)\n",
    "net.cuda(0)\n",
    "\n",
    "#create validation set\n",
    "val_mask=np.random.choice(num_val, val_size)\n",
    "X_val, y_val = create_val(val_mask)\n",
    "X_val = Variable(X_val.cuda(0), requires_grad=False)\n",
    "\n",
    "prev_time = time.clock()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=reg)\n",
    "net.zero_grad()\n",
    "for i in range(21):  # loop over the dataset multiple times\n",
    "    X_batch=None\n",
    "    batch_time=time.clock()\n",
    "    X_batch, y_batch=Process1(i, batch_size)\n",
    "    print (X_batch.size())\n",
    "    print(\"batch_time: \"+ str(time.clock()-batch_time))\n",
    "    X_batch, y_batch = Variable(X_batch.cuda(0)), Variable(y_batch.cuda(0), requires_grad = False)\n",
    "    y_pred = net.forward(X_batch)\n",
    "    y_pred = y_pred.view(-1,5)\n",
    "    loss = F.cross_entropy(y_pred, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    net.zero_grad()\n",
    "    if i % 500 == 0:\n",
    "        print (\"\")\n",
    "        print ('time used %.3f' % (time.clock()-prev_time))\n",
    "        print (str(float(i)/num_times*100)+\"% completed\")\n",
    "        print (loss)\n",
    "        y_val_pred=net.forward(X_val)\n",
    "        y_val_pred=y_val_pred.view(-1,5)\n",
    "        useless, predicted=torch.max(y_val_pred.data, 1)\n",
    "        correct = (predicted == y_val.cuda(0)).sum()\n",
    "        print('Validation accuracy:', float(correct)/val_size)\n",
    "print (\"phase1 successfully trained!\")\n",
    "#torch.save(net.state_dict(), \"premature_net.txt\")\n",
    "print (\"phase1 successfully saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
