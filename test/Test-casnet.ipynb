{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[14]:\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TwoPathConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoPathConv, self).__init__()\n",
    "        self.local_conv1 = nn.Conv2d(4, 64, 7, padding = 16)\n",
    "        #self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.local_conv2 = nn.Conv2d(64, 64, 3)\n",
    "        #self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.local_conv3 = nn.Conv2d(4, 160, 13, padding = 16)\n",
    "        #self.bn3 = nn.BatchNorm2d(160)\n",
    "        self.total_conv = nn.Conv2d(224, 5, 21)\n",
    "\n",
    "    def forward(self, x):\n",
    "        under_x = F.relu(self.local_conv3(x))\n",
    "        x = self.local_conv1(x)\n",
    "        #x = self.bn1(x)\n",
    "        x = F.max_pool2d(F.relu(x), 4, stride = 1)\n",
    "        x = self.local_conv2(x)\n",
    "        #x = self.bn2(x)\n",
    "        x = F.max_pool2d(F.relu(x), 2, stride = 1)\n",
    "        x = torch.cat((x, under_x), 1)\n",
    "        x = self.total_conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "class TwoPathConv_alter(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoPathConv_alter, self).__init__()\n",
    "        self.upper_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(9,64,7, padding = 16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((4,4),stride = 1)\n",
    "        )\n",
    "        self.upper_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2),stride = 1)\n",
    "        )\n",
    "        self.under_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(9,160,13, padding = 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.final_layer = nn.Conv2d(224,5,21)\n",
    "    def forward(self, x):\n",
    "        upper_x = self.upper_layer2(self.upper_layer1(x))\n",
    "        under_x = self.under_layer1(x)\n",
    "        out = torch.cat((under_x, upper_x), 1)\n",
    "        return out    \n",
    "    \n",
    "class Cascaded(nn.Module):\n",
    "    def __init__(self, net1, net2):\n",
    "        super(Cascaded, self).__init__()\n",
    "        self.twopathconv1 = net1\n",
    "        self.twopathconv2 = net2\n",
    "        self.final_layer = nn.Conv2d(224, 5, 21)\n",
    "    def forward(self, x1, x2):\n",
    "        upper_x = self.twopathconv1(x1)\n",
    "        lower_x = torch.cat((upper_x, x2), 1)\n",
    "        final_x = self.twopathconv2(lower_x)\n",
    "        out = self.final_layer(final_x)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "import h5py\n",
    "#challenge_f = h5py.File('Challenge.h5', 'r') #load challenge data\n",
    "train_f = h5py.File('train.h5', 'r')\n",
    "SAMPLE = [ \"LG/0001\", \"LG/0002\", \"LG/0004\", \"LG/0006\", \"LG/0008\", \"LG/0011\",\n",
    "          \"LG/0012\", \"LG/0013\", \"LG/0014\", \"LG/0015\", \"HG/0001\", \"HG/0002\",\n",
    "          \"HG/0003\", \"HG/0004\", \"HG/0005\", \"HG/0006\", \"HG/0007\", \"HG/0008\",\n",
    "          \"HG/0009\", \"HG/0010\", \"HG/0011\", \"HG/0012\", \"HG/0013\", \"HG/0014\",\n",
    "          \"HG/0015\", \"HG/0022\", \"HG/0024\", \"HG/0025\", \"HG/0026\", \"HG/0027\",]\n",
    "'''\n",
    "train_f = h5py.File('Challenge.h5', 'r')\n",
    "SAMPLE = [ \"HG/0301\", \"HG/0302\",\n",
    "          \"HG/0303\", \"HG/0304\", \"HG/0305\", \"HG/0306\", \"HG/0307\", \"HG/0308\",\n",
    "          \"HG/0309\", \"HG/0310\", ]\n",
    "'''\n",
    "#for i in enumerate(SAMPLE):\n",
    "#    index, case = i\n",
    "#    case1 = case[:2]\n",
    "#    case2 = case[3:]\n",
    "#    print(challenge_f[case1][case2].shape)\n",
    "    \n",
    "def create_test_batch(img = 0, x = 16, z= 0):\n",
    "    case = SAMPLE[img]\n",
    "    case1 = case[:2]\n",
    "    case2 = case[3:]\n",
    "    batch = []\n",
    "    _, X, Y, Z = train_f[case1][case2].shape\n",
    "    for y in range(16, Y - 16):\n",
    "        batch.append(train_f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "    batch = torch.from_numpy(np.array(batch))\n",
    "    return batch\n",
    "\n",
    "def create_test_batch_cas(img = 0, x = 32, z= 0):\n",
    "    case = SAMPLE[img]\n",
    "    case1 = case[:2]\n",
    "    case2 = case[3:]\n",
    "    batch = []\n",
    "    _, X, Y, Z = train_f[case1][case2].shape\n",
    "    img1 = train_f[case1][case2][:,:,:,z]\n",
    "    img1 = np.pad(img1, pad_width = ((0,0), (32,32), (32,32)), mode = 'constant')\n",
    "    for y in range(32, Y + 32):\n",
    "        batch.append(img1[:, x-32:x+33, y-32:y+33])\n",
    "    batch = torch.from_numpy(np.array(batch))\n",
    "    return batch, img1\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cascaded (\n",
       "  (twopathconv1): TwoPathConv (\n",
       "    (local_conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(1, 1), padding=(16, 16))\n",
       "    (local_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (local_conv3): Conv2d(4, 160, kernel_size=(13, 13), stride=(1, 1), padding=(16, 16))\n",
       "    (total_conv): Conv2d(224, 5, kernel_size=(21, 21), stride=(1, 1))\n",
       "  )\n",
       "  (twopathconv2): TwoPathConv_alter (\n",
       "    (upper_layer1): Sequential (\n",
       "      (0): Conv2d(9, 64, kernel_size=(7, 7), stride=(1, 1), padding=(16, 16))\n",
       "      (1): ReLU ()\n",
       "      (2): MaxPool2d (size=(4, 4), stride=(1, 1), dilation=(1, 1))\n",
       "    )\n",
       "    (upper_layer2): Sequential (\n",
       "      (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (1): ReLU ()\n",
       "      (2): MaxPool2d (size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
       "    )\n",
       "    (under_layer1): Sequential (\n",
       "      (0): Conv2d(9, 160, kernel_size=(13, 13), stride=(1, 1), padding=(16, 16))\n",
       "      (1): ReLU ()\n",
       "    )\n",
       "    (final_layer): Conv2d(224, 5, kernel_size=(21, 21), stride=(1, 1))\n",
       "  )\n",
       "  (final_layer): Conv2d(224, 5, kernel_size=(21, 21), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "net1 = TwoPathConv()\n",
    "net2 = TwoPathConv_alter()\n",
    "cas_net = Cascaded(net1, net2)\n",
    "#net.load_state_dict(torch.load('phase2_input_cas_net.txt'))\n",
    "cas_net.load_state_dict(torch.load('phase2_transfer_cas_net.txt'))\n",
    "cas_net.cuda(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160 216 176\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /home/yiqin/pytorch/torch/lib/THC/generic/THCStorage.cu:66",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a37e4bff457c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_test_batch_cas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcas_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-50ce11b0fb29>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mupper_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwopathconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mlower_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupper_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mfinal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwopathconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlower_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-50ce11b0fb29>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0munder_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_conv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_conv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m#x = self.bn1(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreshold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/thnn/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, threshold, value, inplace)\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /home/yiqin/pytorch/torch/lib/THC/generic/THCStorage.cu:66"
     ]
    }
   ],
   "source": [
    "prev_time = time.clock()\n",
    "#print(matrix_pred)\n",
    "s = 0\n",
    "#matrix_pred = {}\n",
    "pred = {}\n",
    "matrix_pred ={}\n",
    "\n",
    "for img in range(10,11):\n",
    "    case = SAMPLE[img]\n",
    "    case1 = case[:2]\n",
    "    case2 = case[3:]\n",
    "    #_, X, Y, Z = challenge_f[case1][case2].shape\n",
    "    _, X, Y, Z = train_f[case1][case2].shape\n",
    "    print(X, Y, Z)\n",
    "    matrix_pred[img] = []\n",
    "    #for x in range(16, X - 16):\n",
    "    for x in range(32, X + 32):\n",
    "        pred[(img,x)] = []\n",
    "        for z in range(100,101):\n",
    "            s += 1\n",
    "            #X_batch = create_test_batch(img = img, x = x, z = z)\n",
    "            X_batch, img1 = create_test_batch_cas(img = img, x = x, z = z)\n",
    "            X_batch = Variable(X_batch.cuda(1))\n",
    "            y_pred = cas_net.forward(X_batch,X_batch)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            if (s%10 == 0):\n",
    "                print ('Ongoing ...' ,(img, x, z))\n",
    "                print ('time used %.3f' % (time.clock()-prev_time))\n",
    "            pred[(img,x)].append(y_pred.argmax(axis = 1)) \n",
    "        matrix_pred[img].append(pred[(img,x)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAD8CAYAAADOg5fGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ1SSGhiiktTg/wFtscG3/CA9tgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7f341da630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = 10\n",
    "matrix_pred[img] = np.array(matrix_pred[img])\n",
    "plt.imshow(matrix_pred[img][:,0,:,0,0], cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_patch_size = 256\n",
    "iteration = len(val_list) // val_patch_size\n",
    "prev_time = time.clock()\n",
    "correct = 0\n",
    "for j in range(iteration):\n",
    "    val_x, val_y = create_val_patch(val_patch_size, key = j)\n",
    "    val_x, val_y = Variable(val_x.cuda(3)), val_y.cuda(3)\n",
    "    #train\n",
    "    #check accuracy\n",
    "    val_pred = net.forward(val_x)\n",
    "    val_pred = val_pred.view(-1, 5)\n",
    "    _, predicted = torch.max(val_pred.data, 1)\n",
    "    correct += (predicted == val_y).sum()\n",
    "    total_test_size = val_patch_size * (j+1)\n",
    "    if j % 10 == 0:\n",
    "        print('iteration %d /%d:'%(j, iteration))\n",
    "        print(float(j)/iteration,  'finished')\n",
    "        print('Validation accuracy:', float(correct) / total_test_size)\n",
    "        print('time used:%.3f'% (time.clock() - prev_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputCasNet (\n",
       "  (first_upper_layer1): Sequential (\n",
       "    (0): Conv2d(4, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(4, 4), stride=(1, 1), dilation=(1, 1))\n",
       "  )\n",
       "  (first_upper_layer2): Sequential (\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
       "  )\n",
       "  (first_under_layer1): Sequential (\n",
       "    (0): Conv2d(4, 160, kernel_size=(13, 13), stride=(1, 1))\n",
       "    (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "  )\n",
       "  (first_final_layer): Conv2d(224, 5, kernel_size=(21, 21), stride=(1, 1))\n",
       "  (second_upper_layer1): Sequential (\n",
       "    (0): Conv2d(9, 64, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(4, 4), stride=(1, 1), dilation=(1, 1))\n",
       "  )\n",
       "  (second_upper_layer2): Sequential (\n",
       "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "    (3): MaxPool2d (size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
       "  )\n",
       "  (second_under_layer1): Sequential (\n",
       "    (0): Conv2d(9, 160, kernel_size=(13, 13), stride=(1, 1))\n",
       "    (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "  )\n",
       "  (under_layer1): Sequential (\n",
       "    (0): Conv2d(9, 160, kernel_size=(13, 13), stride=(1, 1))\n",
       "    (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True)\n",
       "    (2): ReLU ()\n",
       "  )\n",
       "  (second_final_layer): Conv2d(224, 5, kernel_size=(21, 21), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cas-net test\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.init as ini\n",
    "import multiprocessing\n",
    "from multiprocessing import Queue\n",
    "import random\n",
    "from random import shuffle\n",
    "import pickle\n",
    "\n",
    "class InputCasNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InputCasNet, self).__init__()\n",
    "        self.first_upper_layer1=nn.Sequential(\n",
    "            nn.Conv2d(4,64,7),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((4,4),stride = 1)\n",
    "        )\n",
    "        self.first_upper_layer2=nn.Sequential(\n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2),stride = 1)\n",
    "        )\n",
    "        self.first_under_layer1=nn.Sequential(\n",
    "            nn.Conv2d(4,160,13),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.first_final_layer=nn.Conv2d(224,5,21)\n",
    "        \n",
    "        self.second_upper_layer1=nn.Sequential(\n",
    "            nn.Conv2d(9,64,7),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((4,4),stride = 1)\n",
    "        )\n",
    "        self.second_upper_layer2=nn.Sequential(\n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2),stride = 1)\n",
    "        )\n",
    "        self.second_under_layer1=self.under_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(9,160,13),\n",
    "            nn.BatchNorm2d(160),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.second_final_layer = nn.Conv2d(224,5,21)\n",
    "    \n",
    "    def forward(self, x1):\n",
    "        upper_x=self.first_upper_layer2(self.first_upper_layer1(x1))\n",
    "        under_x=self.first_under_layer1(x1)\n",
    "        x=torch.cat((upper_x, under_x), 1)\n",
    "        x=self.first_final_layer(x)\n",
    "        x2=x1[:, :, 16:48+1, 16:48+1]*1.0\n",
    "        x2=torch.cat((x, x2), 1)\n",
    "        upper_x2=self.second_upper_layer2(self.second_upper_layer1(x2))\n",
    "        under_x2=self.second_under_layer1(x2)\n",
    "        x3=torch.cat((upper_x2, under_x2), 1)\n",
    "        x3=self.second_final_layer(x3)\n",
    "        return x3\n",
    "\n",
    "cas_net=InputCasNet()\n",
    "cas_net.load_state_dict(torch.load('phase1_input_cas_net.txt'))\n",
    "cas_net.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
