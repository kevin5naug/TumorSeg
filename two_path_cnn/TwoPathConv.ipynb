{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.init as ini\n",
    "import multiprocessing\n",
    "from multiprocessing import Queue\n",
    "import random\n",
    "\n",
    "class TwoPathConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoPathConv, self).__init__()\n",
    "        self.local_conv1 = nn.Conv2d(2, 64, 7)\n",
    "        self.local_conv2 = nn.Conv2d(64, 64, 3)\n",
    "        self.local_conv3 = nn.Conv2d(2, 160, 13)\n",
    "        self.total_conv = nn.Conv2d(224, 5, 21)\n",
    "\n",
    "    def forward(self, x):\n",
    "        under_x = F.relu(self.local_conv3(x))\n",
    "        x = self.local_conv1(x)\n",
    "        x = F.max_pool2d(F.relu(x), 4, stride = 1)\n",
    "        x = self.local_conv2(x)\n",
    "        x = F.max_pool2d(F.relu(x), 2, stride = 1)\n",
    "        x = torch.cat((x, under_x), 1)\n",
    "        x = self.total_conv(x)\n",
    "        x = x.view(-1,5)\n",
    "        return x\n",
    "\n",
    "# In[3]:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = open('/home/yiqin/trainval-balanced.txt','r')\n",
    "f = h5py.File('/home/yiqin/train.h5','r')\n",
    "list1 = []\n",
    "str1 = file_list.readlines()\n",
    "for i in range(len(str1)):\n",
    "    list1.append(str1[i][0:-1].split(' '))\n",
    "print(len(list1))\n",
    "\n",
    "import pickle as pkl\n",
    "input1 = open('two_path_cnn/HG0001_Val_list.pkl', 'rb')\n",
    "input2 = open('two_path_cnn/training_list.pkl', 'rb')\n",
    "val_list = pkl.load(input1)\n",
    "train_list = pkl.load(input2)\n",
    "print(len(val_list))\n",
    "\n",
    "\n",
    "#without multiprocessing\n",
    "def create_sub_patch_phase1(size, key):\n",
    "    training_patch = []\n",
    "    training_label = []\n",
    "    len_data = len(train_list)\n",
    "    for i in range(size):\n",
    "        case,x,y,z,l = train_list[key * size + i]\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        content = f[case1][case2]\n",
    "        img_patch = content[0:2, x-16:x+16+1, y-16:y+16+1, z] #sample a 33x33 patch\n",
    "        training_patch.append(img_patch)\n",
    "        training_label.append(l)\n",
    "    train_patch = torch.from_numpy(np.array(training_patch))\n",
    "    train_label = torch.from_numpy(np.array(training_label))\n",
    "    return train_patch, train_label\n",
    "\n",
    "\n",
    "def create_val_patch(size):\n",
    "    val_patch = []\n",
    "    val_label = []\n",
    "    len_data = len(val_list)\n",
    "    for i in range(size*2, size*3):\n",
    "        case,x,y,z,l = val_list[i]\n",
    "        #print(i, key)\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        content = f[case1][case2]\n",
    "        img_patch = content[0:2, x-16:x+16+1, y-16:y+16+1, z] #sample a 33x33 patch\n",
    "        val_patch.append(img_patch)\n",
    "        val_label.append(l)\n",
    "    val_patch = torch.from_numpy(np.array(val_patch))\n",
    "    val_label = torch.from_numpy(np.array(val_label))\n",
    "    return val_patch, val_label\n",
    "\n",
    "\n",
    "prev_time = time.clock()\n",
    "num_epoch = 5\n",
    "batch_size = 512\n",
    "iteration = len(train_list) // batch_size\n",
    "net = TwoPathConv()\n",
    "#net.load_state_dict(torch.load('/home/yiqin/phase1_TwoPathConv_net.txt'))\n",
    "net = net.cuda(0)\n",
    "\n",
    "#net init\n",
    "'''\n",
    "for param in net.parameters():\n",
    "    if len(param.size())==4:\n",
    "        ini.uniform(param, a=-5e-3, b=5e-3)\n",
    "'''        \n",
    "#set hyperparams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-6\n",
    "l1_reg = 5e-7\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum = 0.9, weight_decay = 5e-5)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=0.2)\n",
    "#create val set\n",
    "val_patch_size = 512\n",
    "val_x, val_y = create_val_patch(val_patch_size)\n",
    "val_x, val_y = Variable(val_x.cuda(0)), val_y.cuda(0)\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    for j in range(iteration):\n",
    "        training_patch, training_label = create_sub_patch_phase1(batch_size, j)\n",
    "        x_train, y_train = Variable(training_patch.cuda(0)), Variable(training_label.cuda(0), requires_grad=False)\n",
    "        #train\n",
    "        y_pred = net.forward(x_train)\n",
    "        y_pred = y_pred.view(-1,5)\n",
    "        loss = F.cross_entropy(y_pred, y_train)#cross entropy loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #check accuracy\n",
    "        if j%10 == 0:\n",
    "            print('iteration %d /%d:'%(j, iteration), loss.data)\n",
    "            print(float(j)/(iteration * num_epoch),  'finished')\n",
    "            val_pred = net.forward(val_x)\n",
    "            val_pred = val_pred.view(-1, 5)\n",
    "            _, predicted = torch.max(val_pred.data, 1)\n",
    "            correct = (predicted == val_y).sum()\n",
    "            print('Validation accuracy:', float(correct) / val_patch_size)\n",
    "            print('time used:%.3f'% (time.clock() - prev_time))\n",
    "    scheduler.step()\n",
    "    output = \"/home/yiqin/two_path_cnn/p1_TPWconv_net\" + str(i) + '.txt'\n",
    "    torch.save(net.state_dict(), output)\n",
    "    \n",
    "print (\"phase1: successfully trained!\")\n",
    "\n",
    "print (\"phase1: successfully saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def create_patch(f, file_list, patch_size = 100):\n",
    "    training_patch = []\n",
    "    training_label = []\n",
    "    for i in range(patch_size):\n",
    "        index = random.randint(0, len(file_list))\n",
    "        case,x,y,z,l = file_list[index]\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        img_patch = f[case1][case2][:, x-16:x+16+1, y-16:y+16+1, z] #sample a 33x33 patch\n",
    "        training_patch.append(img_patch)\n",
    "        training_label.append(l)\n",
    "    training_patch = torch.from_numpy(np.array(training_patch))\n",
    "    training_label = torch.from_numpy(np.array(training_label))\n",
    "    return training_patch, training_label\n",
    "\n",
    "def create_val_patch(f, file_list, step = 10000, key = 9999):\n",
    "    val_patch = []\n",
    "    val_label = []\n",
    "    patch_size = len(file_list) // step\n",
    "    for i in range(patch_size):\n",
    "        case,x,y,z,l = file_list[i * step + key]\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        img_patch = f[case1][case2][:, x-16:x+16+1, y-16:y+16+1, z] #sample a 33x33 patch\n",
    "        val_patch.append(img_patch)\n",
    "        val_label.append(l)\n",
    "    val_patch = torch.from_numpy(np.array(val_patch))\n",
    "    val_label = torch.from_numpy(np.array(val_label))\n",
    "    return val_patch, val_label\n",
    "# subsampling\n",
    "def create_sub_patch(f, file_list, step = 100, key = 0):\n",
    "    training_patch = []\n",
    "    training_label = []\n",
    "    patch_size = len(file_list) // step\n",
    "    for i in range(patch_size):\n",
    "        case,x,y,z,l = file_list[i * step + key]\n",
    "        #print(i, key)\n",
    "        x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "        case1 = case[0:2]\n",
    "        case2 = case[3:]\n",
    "        img_patch = f[case1][case2][:, x-16:x+16+1, y-16:y+16+1, z] #sample a 33x33 patch\n",
    "        training_patch.append(img_patch)\n",
    "        training_label.append(l)\n",
    "    training_patch = torch.from_numpy(np.array(training_patch))\n",
    "    training_label = torch.from_numpy(np.array(training_label))\n",
    "    return training_patch, training_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#1 phase train\n",
    "import h5py\n",
    "file_list = open('trainval-balanced.txt','r')\n",
    "f = h5py.File('training.h5','r')\n",
    "list1 = []\n",
    "str1 = file_list.readlines()\n",
    "for i in range(len(str1)):\n",
    "    list1.append(str1[i][0:-1].split(' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train & validation\n",
    "import numpy as np\n",
    "import time\n",
    "net = torch.load('prematrue_net.pkl')\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "epoch_start = 1000\n",
    "epoch_end = 2000\n",
    "train_patch_size = len(list1) //  20000\n",
    "val_patch_size = len(list1) //  20000\n",
    "net.cuda(1)\n",
    "prev_time = time.clock()\n",
    "for i in range(epoch_start, epoch_end):\n",
    "    training_patch, training_label = create_sub_patch(f = f, file_list = list1, step = 20000, key = i)\n",
    "    x_train, y_train = Variable(training_patch.cuda(1)), Variable(training_label.cuda(1), requires_grad=False)\n",
    "    #train\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = net.forward(x_train)\n",
    "    y_pred = y_pred.view(train_patch_size,5)\n",
    "    loss = F.cross_entropy(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    print(loss)\n",
    "    optimizer.step()\n",
    "    #check accuracy\n",
    "    val_patch, val_y = create_val_patch(f = f, file_list = list1, step = 20000, key = 5000)\n",
    "    val_y = val_y.view((val_patch_size,1))\n",
    "    val_x = Variable(val_patch.cuda(1))\n",
    "    val_pred = net.forward(val_x)\n",
    "    val_pred = val_pred.view(val_patch_size, 5)\n",
    "    _, predicted = torch.max(val_pred.data, 1)\n",
    "    #print(type(predicted))\n",
    "    total = val_patch_size\n",
    "    correct = (predicted == val_y.cuda(1)).sum()\n",
    "    print 'epoch: %d'%i \n",
    "    print'Validation accuracy:', float(correct) / total\n",
    "    print'time used:%.3f'% (time.clock() - prev_time)\n",
    "torch.save(net, 'premature_net.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd phase train\n",
    "import h5py\n",
    "normal_list = open('trainval.txt','r')\n",
    "f = h5py.File('training.h5','r')\n",
    "list2 = []\n",
    "str2 = normal_list.readlines()\n",
    "for i in range(len(str2)):\n",
    "    list2.append(str2[i][0:-1].split(' '))\n",
    "print(len(list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check accuracy\n",
    "import numpy as np\n",
    "import time\n",
    "net = TwoPathConv()\n",
    "net.load_state_dict(torch.load(\"trained_model.txt\"))\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "val_patch_size = len(list2) //  20000\n",
    "num_epoch = 1\n",
    "train_patch_size = 500\n",
    "net.cuda(1)\n",
    "prev_time = time.clock()\n",
    "for i in range(num_epoch):\n",
    "    #check accuracy\n",
    "    val_patch, val_y = create_val_patch(f = f, file_list = list2, step = 20000)\n",
    "    val_y = val_y.view((val_patch_size,1))\n",
    "    val_x = Variable(val_patch.cuda(1))\n",
    "    val_pred = net.forward(val_x)\n",
    "    #print(val_pred)\n",
    "    #print('-------------')\n",
    "    #print(val_y)\n",
    "    val_pred = val_pred.view(val_patch_size, 5)\n",
    "    _, predicted = torch.max(val_pred.data, 1)\n",
    "    #print(type(predicted))\n",
    "    total = float(val_patch_size)\n",
    "    correct = (predicted == val_y.cuda(1)).sum()\n",
    "    print'Validation accuracy:', float(correct) / total\n",
    "    print'time used:%.3f'% (time.clock() - prev_time)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "f = h5py.File('/Users/Fischer/Tumor/TumorSeg/data/training.h5','r')\n",
    "list1 = []\n",
    "str1 = file_list.readlines()\n",
    "for i in range(len(str1)):\n",
    "    list1.append(str1[i][0:-1].split(' '))\n",
    "print(len(list1))\n",
    "training_patch = []\n",
    "training_label = []\n",
    "for i in range(100):\n",
    "    case,x,y,z,l = list1[i]\n",
    "    x,y,z,l = int(x), int(y), int(z), int(l)\n",
    "    case1 = case[0:2]\n",
    "    case2 = case[3:]\n",
    "    img_patch = f[case1][case2][:, x-16:x+16+1, y-16:y+16+1, z] #sample a 33x33 patch\n",
    "    training_patch.append(img_patch)\n",
    "    training_label.append(l)\n",
    "training_patch = np.array(training_patch)\n",
    "training_label = np.array(training_label)\n",
    "\n",
    "print(training_patch[0])\n",
    "print(training_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medpy.io import load\n",
    "img = load('VSD.Brain.XX.O.MR_Flair.865.mha')\n",
    "print(img)\n",
    "#plt.imshow(array_image2[30,:,:], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "input_image = sitk.ReadImage('VSD.Brain.XX.O.MR_Flair.17572.mha')\n",
    "image_2D = sitk.Image(64, 64, sitk.sitkFloat32)\n",
    "print(input_image.GetSize())\n",
    "#help(image_2D)\n",
    "array_image = sitk.GetArrayFromImage(input_image)\n",
    "print(array_image[50,50,:])\n",
    "variable_image = Variable(torch.from_numpy(array_image))\n",
    "#print(variable_image)\n",
    "\n",
    "plt.imshow(array_image[30,:,:], cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "r\"\"\"Convert nii to hdf5 file.\n",
    "\n",
    "Example usage:\n",
    "    ./create_h5.py --data_dir=/path/to/data_dir_contain_HG_and_LG \\\n",
    "        --output_path=/path/to/h5_file\n",
    "\"\"\"\n",
    "import os.path as osp\n",
    "import argparse\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "\n",
    "# SAMPLE and MODALITY\n",
    "SAMPLE = [\"LG/0001\", \"LG/0002\", \"LG/0004\", \"LG/0006\", \"LG/0008\", \"LG/0011\",\n",
    "          \"LG/0012\", \"LG/0013\", \"LG/0014\", \"LG/0015\", \"HG/0001\", \"HG/0002\",\n",
    "          \"HG/0003\", \"HG/0004\", \"HG/0005\", \"HG/0006\", \"HG/0007\", \"HG/0008\",\n",
    "          \"HG/0009\", \"HG/0010\", \"HG/0011\", \"HG/0012\", \"HG/0013\", \"HG/0014\",\n",
    "          \"HG/0015\", \"HG/0022\", \"HG/0024\", \"HG/0025\", \"HG/0026\", \"HG/0027\"]\n",
    "MODALITY = [\"Flair.finalNorm.nii.gz\", \"T1.finalNorm.nii.gz\",\n",
    "            \"T1c.finalNorm.nii.gz\", \"T2.finalNorm.nii.gz\"]\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\" Parse args.\n",
    "    \"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--data_dir', dest='input_dir',\n",
    "                        help='dir for training nii data',\n",
    "                        default='training', type=str)\n",
    "    parser.add_argument('--output_path', dest='output_path',\n",
    "                        help='output path for h5 file',\n",
    "                        default='training.h5', type=str)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "def get_img_data(data_dir, sample, modality):\n",
    "    \"\"\"Get image data.\n",
    "    \"\"\"\n",
    "    nii_path = osp.join(data_dir, sample, modality)\n",
    "    img = nib.load(nii_path)\n",
    "    return img.get_data()\n",
    "\n",
    "def main():\n",
    "    \"\"\"main loop\n",
    "    \"\"\"\n",
    "    args = parse_args()\n",
    "    data_dir = args.input_dir\n",
    "    with h5py.File(args.output_path, 'w') as f:\n",
    "        for path in SAMPLE:\n",
    "            img_data = get_img_data(data_dir, path, MODALITY[0])\n",
    "            dim = img_data.shape\n",
    "            img_array = np.empty((4, dim[0], dim[1], dim[2]), dtype=np.float32)\n",
    "            img_array[0, ...] = img_data\n",
    "            for j in range(1, len(MODALITY)-1):\n",
    "                img_array[j, ...] = get_img_data(data_dir, path, MODALITY[j])\n",
    "            f[path] = img_array\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
