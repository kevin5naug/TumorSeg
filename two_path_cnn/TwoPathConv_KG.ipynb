{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwoPathConv (\n",
      "  (upper_layer1): Sequential (\n",
      "    (0): Conv2d(4, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(4, 4), stride=(1, 1), dilation=(1, 1))\n",
      "  )\n",
      "  (upper_layer2): Sequential (\n",
      "    (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (1): ReLU ()\n",
      "    (2): MaxPool2d (size=(2, 2), stride=(1, 1), dilation=(1, 1))\n",
      "  )\n",
      "  (under_layer1): Sequential (\n",
      "    (0): Conv2d(4, 160, kernel_size=(13, 13), stride=(1, 1))\n",
      "    (1): ReLU ()\n",
      "  )\n",
      "  (final_layer): Conv2d(224, 5, kernel_size=(21, 21), stride=(1, 1))\n",
      ")\n",
      "Variable containing:\n",
      "(0 ,0 ,.,.) = \n",
      " -0.2936\n",
      "\n",
      "(0 ,1 ,.,.) = \n",
      " -0.0713\n",
      "\n",
      "(0 ,2 ,.,.) = \n",
      "  0.1108\n",
      "\n",
      "(0 ,3 ,.,.) = \n",
      "  0.5662\n",
      "\n",
      "(0 ,4 ,.,.) = \n",
      "  0.0497\n",
      "[torch.FloatTensor of size 1x5x1x1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class TwoPathConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoPathConv, self).__init__()\n",
    "        self.upper_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(4,64,7),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((4,4),stride = 1)\n",
    "        )\n",
    "        self.upper_layer2 = nn.Sequential(\n",
    "            nn.Conv2d(64,64,3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2),stride = 1)\n",
    "        )\n",
    "        self.under_layer1 = nn.Sequential(\n",
    "            nn.Conv2d(4,160,13),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.final_layer = nn.Conv2d(224,5,21)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        upper_x = self.upper_layer2(self.upper_layer1(x))\n",
    "        under_x = self.under_layer1(x)\n",
    "        #upper_x = F.max_pool2d(F.relu(self.upper_conv1(x)), (4, 4),stride = 1)\n",
    "        #upper_x = F.max_pool2d(F.relu(self.upper_conv2(upper_x)), (2, 2), stride = 1)\n",
    "        #under_x = F.relu(self.under_conv1(x))\n",
    "        final_x = torch.cat((under_x, upper_x), 1)\n",
    "        out = self.final_layer(final_x)\n",
    "        return out\n",
    "        \n",
    "net = TwoPathConv()\n",
    "print(net)\n",
    "\n",
    "x = Variable(torch.randn(1,4,33,33), requires_grad = True)\n",
    "y_pred = net.forward(x)\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase 1 data preparation process completed.\n",
      "phase 2 data preparation process completed.\n"
     ]
    }
   ],
   "source": [
    "#get the training set for phase 1\n",
    "f=open(\"trainval-balanced.txt\", \"r\")\n",
    "content=f.readlines()\n",
    "data=[]\n",
    "data_train_phase1=[]\n",
    "i=0\n",
    "for line in content:\n",
    "    no_n_line=line[0:len(line)-1]\n",
    "    item=no_n_line.split(\" \")\n",
    "    data.append([])\n",
    "    data[i].append(item[0])\n",
    "    data[i].append(int(item[1]))\n",
    "    data[i].append(int(item[2]))\n",
    "    data[i].append(int(item[3]))\n",
    "    data[i].append(int(item[4]))\n",
    "    data_train_phase1.append(data[i])\n",
    "    i += 1\n",
    "f.close()\n",
    "print \"phase 1 data preparation process completed.\"\n",
    "\n",
    "#get the training set for phase 2 and the validation set\n",
    "data_val=[]\n",
    "f_in=open(\"trainval.txt\", \"r\")\n",
    "content=f_in.readlines()\n",
    "data=[]\n",
    "data_val=[]\n",
    "data_train_phase2=[]\n",
    "i=0\n",
    "for line in content:\n",
    "    no_n_line=line[0:len(line)-1]\n",
    "    item=no_n_line.split(\" \")\n",
    "    data.append([])\n",
    "    data[i].append(item[0])\n",
    "    data[i].append(int(item[1]))\n",
    "    data[i].append(int(item[2]))\n",
    "    data[i].append(int(item[3]))\n",
    "    data[i].append(int(item[4]))\n",
    "    if i%30000==0:\n",
    "        data_val.append(data[i])\n",
    "    else:\n",
    "        data_train_phase2.append(data[i])\n",
    "    i += 1\n",
    "f_in.close()\n",
    "print \"phase 2 data preparation process completed.\"\n",
    "\n",
    "import h5py\n",
    "f = h5py.File('training.h5','r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-f69bfa783da2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_phase1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train_phase2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "print len(data)\n",
    "print len(data_val)\n",
    "print len(data_train_phase1)\n",
    "print len(data_train_phase2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 216, 196, 176)\n",
      "(4, 216, 236, 176)\n",
      "(4, 216, 236, 176)\n",
      "(4, 159, 216, 196)\n",
      "(4, 216, 236, 176)\n",
      "(4, 162, 230, 230)\n",
      "(4, 230, 230, 165)\n",
      "(4, 168, 220, 220)\n",
      "(4, 162, 230, 230)\n",
      "(4, 230, 230, 163)\n",
      "(4, 160, 216, 176)\n",
      "(4, 160, 216, 176)\n",
      "(4, 176, 216, 176)\n",
      "(4, 160, 216, 176)\n",
      "(4, 160, 216, 176)\n",
      "(4, 216, 236, 176)\n",
      "(4, 176, 216, 176)\n",
      "(4, 160, 216, 176)\n",
      "(4, 160, 216, 176)\n",
      "(4, 160, 216, 176)\n",
      "(4, 176, 216, 176)\n",
      "(4, 176, 216, 176)\n",
      "(4, 176, 216, 176)\n",
      "(4, 176, 216, 176)\n",
      "(4, 160, 216, 176)\n",
      "(4, 230, 230, 165)\n",
      "(4, 168, 240, 240)\n",
      "(4, 162, 230, 230)\n",
      "(4, 168, 220, 220)\n",
      "(4, 162, 230, 230)\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "challenge_f = h5py.File('Challenge.h5', 'r') #load challenge data\n",
    "\n",
    "SAMPLE = [ \"HG/0301\", \"HG/0302\",\n",
    "          \"HG/0303\", \"HG/0304\", \"HG/0305\", \"HG/0306\", \"HG/0307\", \"HG/0308\",\n",
    "          \"HG/0309\", \"HG/0310\", ]\n",
    "for i in enumerate(SAMPLE):\n",
    "    index, case = i\n",
    "    case1 = case[:2]\n",
    "    case2 = case[3:]\n",
    "    print(challenge_f[case1][case2].shape)\n",
    "    \n",
    "def create_test_batch(img = 0, y = 16, z= 0):\n",
    "    case = SAMPLE[img]\n",
    "    case1 = case[:2]\n",
    "    case2 = case[3:]\n",
    "    batch = []\n",
    "    _, X, Y, Z = challenge_f[case1][case2].shape\n",
    "    for x in range(16, X - 17):\n",
    "        batch.append(challenge_f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "    batch = torch.from_numpy(np.array(batch))\n",
    "    return batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(   0   ,.,.) = \n",
      "   0   0   0  ...    0   0   0\n",
      "[torch.cuda.LongTensor of size 1x1x1572864 (GPU 1)]\n",
      "\n",
      "fuck\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'dtype' is an invalid keyword argument for this function",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-24f26acf7a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m#p = (out==i)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#pt = torch.mul(p,t)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dtype' is an invalid keyword argument for this function"
     ]
    }
   ],
   "source": [
    "target = Variable(torch.LongTensor(np.zeros((1, 128, 128, 96), dtype = int)), requires_grad = False)\n",
    "target = target.cuda(1)\n",
    "target = target.view(1, 1,-1)\n",
    "#print(out)\n",
    "print(target)\n",
    "print('fuck')\n",
    "loss = Variable(torch.Tensor([0]))\n",
    "for i in range(1):\n",
    "    #p = (out==i)\n",
    "    t = (target==i)\n",
    "    t = Variable(t, dtype = int)\n",
    "    #pt = torch.mul(p,t)\n",
    "    print(t)\n",
    "    print(F.avg_pool1d(t, kernel_size = 1572864) * 1572864)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158, 180, 140)\n",
      "Ongoing ... (0, 16, 0)\n",
      "time used 0.659\n",
      "Ongoing ... (0, 16, 1)\n",
      "time used 0.865\n",
      "Ongoing ... (0, 16, 2)\n",
      "time used 1.071\n",
      "Ongoing ... (0, 16, 3)\n",
      "time used 1.289\n",
      "Ongoing ... (0, 16, 4)\n",
      "time used 1.504\n",
      "Ongoing ... (0, 16, 5)\n",
      "time used 1.727\n",
      "Ongoing ... (0, 16, 6)\n",
      "time used 1.941\n",
      "Ongoing ... (0, 16, 7)\n",
      "time used 2.170\n",
      "Ongoing ... (0, 16, 8)\n",
      "time used 2.391\n",
      "Ongoing ... (0, 16, 9)\n",
      "time used 2.618\n",
      "Ongoing ... (0, 16, 10)\n",
      "time used 2.837\n",
      "Ongoing ... (0, 16, 11)\n",
      "time used 3.064\n",
      "Ongoing ... (0, 16, 12)\n",
      "time used 3.287\n",
      "Ongoing ... (0, 16, 13)\n",
      "time used 3.514\n",
      "Ongoing ... (0, 16, 14)\n",
      "time used 3.729\n",
      "Ongoing ... (0, 16, 15)\n",
      "time used 3.938\n",
      "Ongoing ... (0, 16, 16)\n",
      "time used 4.158\n",
      "Ongoing ... (0, 16, 17)\n",
      "time used 4.558\n",
      "Ongoing ... (0, 16, 18)\n",
      "time used 4.846\n",
      "Ongoing ... (0, 16, 19)\n",
      "time used 5.251\n",
      "Ongoing ... (0, 16, 20)\n",
      "time used 5.646\n",
      "Ongoing ... (0, 16, 21)\n",
      "time used 6.056\n",
      "Ongoing ... (0, 16, 22)\n",
      "time used 6.303\n",
      "Ongoing ... (0, 16, 23)\n",
      "time used 6.559\n",
      "Ongoing ... (0, 16, 24)\n",
      "time used 6.884\n",
      "Ongoing ... (0, 16, 25)\n",
      "time used 7.089\n",
      "Ongoing ... (0, 16, 26)\n",
      "time used 7.291\n",
      "Ongoing ... (0, 16, 27)\n",
      "time used 7.509\n",
      "Ongoing ... (0, 16, 28)\n",
      "time used 7.724\n",
      "Ongoing ... (0, 16, 29)\n",
      "time used 7.954\n",
      "Ongoing ... (0, 16, 30)\n",
      "time used 8.172\n",
      "Ongoing ... (0, 16, 31)\n",
      "time used 8.397\n",
      "Ongoing ... (0, 16, 32)\n",
      "time used 8.617\n",
      "Ongoing ... (0, 16, 33)\n",
      "time used 8.848\n",
      "Ongoing ... (0, 16, 34)\n",
      "time used 9.074\n",
      "Ongoing ... (0, 16, 35)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-fb63c3ed5ce7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m'Ongoing ...'\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_test_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mX_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-11ceaffc1f94>\u001b[0m in \u001b[0;36mcreate_test_batch\u001b[0;34m(img, y, z)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchallenge_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchallenge_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcase2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip_build_root/h5py/h5py/_objects.c:2574)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (/tmp/pip_build_root/h5py/h5py/_objects.c:2533)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/h5py/_hl/dataset.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    449\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "net = TwoPathConv()\n",
    "net.load_state_dict(torch.load('premature_net_phase2_without_biasreg.txt'))\n",
    "net.cuda(3)\n",
    "pred = {}\n",
    "prev_time = time.clock()\n",
    "s = 0\n",
    "for img in range(1):\n",
    "    case = SAMPLE[img]\n",
    "    case1 = case[:2]\n",
    "    case2 = case[3:]\n",
    "    _, X, Y, Z = challenge_f[case1][case2].shape\n",
    "    print(X, Y, Z)\n",
    "    for y in range(16, Y - 17):\n",
    "        for z in range(Z):\n",
    "            s += 1\n",
    "            if (s%100 == 0):\n",
    "                print'Ongoing ...' ,(img, y, z)\n",
    "                print 'time used %.3f' % (time.clock()-prev_time)\n",
    "            pred[img] = []\n",
    "            X_batch = create_test_batch(img = img, y = y, z = z)\n",
    "            X_batch = Variable(X_batch.cuda(3))\n",
    "            y_pred = net.forward(X_batch)\n",
    "            y_pred = y_pred.data.cpu().numpy()\n",
    "            pred[img].append(y_pred.max(axis = 1))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn.init as ninit\n",
    "def init_net(net):\n",
    "    for param in net.parameters():\n",
    "        ninit.uniform(param.data, a=-5e-3, b=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_batch_phase1(index, batch_size):\n",
    "    step=len(data_train_phase1)//batch_size\n",
    "    starting_index=index%step\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    while starting_index < len(data_train_phase1):\n",
    "        case, x, y, z, l = data_train_phase1[starting_index]\n",
    "        case1 = case[:2]\n",
    "        case2 = case[3:]\n",
    "        X_batch.append(f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "        y_batch.append(l)\n",
    "        starting_index+=step\n",
    "    X_batch = torch.from_numpy(np.array(X_batch))\n",
    "    y_batch = torch.from_numpy(np.array(y_batch))\n",
    "    return X_batch, y_batch\n",
    "\n",
    "def create_batch_phase2(index, batch_size):\n",
    "    step=len(data_train_phase2)//batch_size\n",
    "    starting_index=index%step\n",
    "    X_batch = []\n",
    "    y_batch = []\n",
    "    while starting_index < len(data_train_phase2):\n",
    "        case, x, y, z, l = data_train_phase2[starting_index]\n",
    "        case1 = case[:2]\n",
    "        case2 = case[3:]\n",
    "        X_batch.append(f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "        y_batch.append(l)\n",
    "        starting_index+=step\n",
    "    X_batch = torch.from_numpy(np.array(X_batch))\n",
    "    y_batch = torch.from_numpy(np.array(y_batch))\n",
    "    return X_batch, y_batch\n",
    "\n",
    "def create_val(batch_mask):\n",
    "    X_val=[]\n",
    "    y_val=[]\n",
    "    for i in range(len(batch_mask)):\n",
    "        case, x, y, z, l = data_val[batch_mask[i]]\n",
    "        case1 = case[:2]\n",
    "        case2 = case[3:]\n",
    "        X_val.append(f[case1][case2][:, x-16:x+17, y-16:y+17, z])\n",
    "        y_val.append(l)\n",
    "    X_val = torch.from_numpy(np.array(X_val))\n",
    "    y_val = torch.from_numpy(np.array(y_val))\n",
    "    return X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55061\n",
      "TwoPathConv (\n",
      "  (upper_conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(1, 1))\n",
      "  (upper_conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (final_layer): Conv2d(64, 5, kernel_size=(21, 21), stride=(1, 1))\n",
      ")\n",
      "Variable containing:\n",
      " 1.6099\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "time used 1.986\n",
      "('Validation accuracy:', 0.7639225181598063)\n",
      "Variable containing:\n",
      " 1.3058\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "time used 20.896\n",
      "('Validation accuracy:', 0.8789346246973365)\n",
      "Variable containing:\n",
      " 0.7006\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "time used 39.665\n",
      "('Validation accuracy:', 0.8789346246973365)\n",
      "Variable containing:\n",
      " 0.4745\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "time used 58.660\n",
      "('Validation accuracy:', 0.8789346246973365)\n",
      "Variable containing:\n",
      " 0.4449\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "time used 77.659\n",
      "('Validation accuracy:', 0.8789346246973365)\n",
      "Variable containing:\n",
      " 0.4377\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "time used 96.598\n",
      "('Validation accuracy:', 0.8789346246973365)\n",
      "Variable containing:\n",
      " 0.3885\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "time used 115.545\n",
      "('Validation accuracy:', 0.8789346246973365)\n",
      "Variable containing:\n",
      " 0.3771\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "time used 134.547\n",
      "('Validation accuracy:', 0.8789346246973365)\n",
      "Variable containing:\n",
      " 0.3663\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "time used 153.455\n",
      "('Validation accuracy:', 0.8789346246973365)\n",
      "Variable containing:\n",
      " 0.3861\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "time used 172.392\n",
      "('Validation accuracy:', 0.8789346246973365)\n",
      "Variable containing:\n",
      " 0.3743\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 2)]\n",
      "\n",
      "time used 191.330\n",
      "('Validation accuracy:', 0.8789346246973365)\n",
      "onephase_net successfully trained!\n",
      "onephase_net successfully saved!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "num_train=len(data_train_phase2)\n",
    "num_val=len(data_val)\n",
    "batch_size=900\n",
    "val_size=num_val\n",
    "num_epoch=2.0\n",
    "num_times=int(float(num_train)/batch_size*num_epoch)\n",
    "print num_times\n",
    "learning_rate = 5e-3\n",
    "reg=5e-5\n",
    "net = TwoPathConv()\n",
    "print(net)\n",
    "init_net(net)\n",
    "net.cuda(2)\n",
    "\n",
    "#create validation set\n",
    "val_mask=np.random.choice(num_val, val_size)\n",
    "X_val, y_val = create_val(val_mask)\n",
    "X_val = Variable(X_val.cuda(2), requires_grad=False)\n",
    "\n",
    "prev_time = time.clock()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=reg)\n",
    "net.zero_grad()\n",
    "for i in xrange(num_times):  # loop over the dataset multiple times\n",
    "    X_batch=None\n",
    "    X_batch, y_batch = create_batch_phase2(i, batch_size)\n",
    "    X_batch, y_batch = Variable(X_batch.cuda(2)), Variable(y_batch.cuda(2), requires_grad = False)\n",
    "    y_pred = net.forward(X_batch)\n",
    "    y_pred = y_pred.view(-1,5)\n",
    "    loss = F.cross_entropy(y_pred, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    net.zero_grad()\n",
    "    if i % 100 == 0:\n",
    "        print loss\n",
    "        print 'time used %.3f' % (time.clock()-prev_time)\n",
    "        y_val_pred=net.forward(X_val)\n",
    "        y_val_pred=y_val_pred.view(-1,5)\n",
    "        useless, predicted=torch.max(y_val_pred.data, 1)\n",
    "        correct = (predicted == y_val.cuda(2)).sum()\n",
    "        print('Validation accuracy:', float(correct)/val_size)\n",
    "print \"onephase_net successfully trained!\"\n",
    "torch.save(net.state_dict(), \"onephase_net.txt\")\n",
    "print \"onephase_net successfully saved!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adam(x, dx, config = None):\n",
    "    if config is None: \n",
    "        config = {}\n",
    "        config.setdefault('learning_rate',1e-4)\n",
    "        config.setdefault('beta1',0.9)\n",
    "        config.setdefault('beta2',0.999)\n",
    "        config.setdefault('epsilon',1e-8)\n",
    "        config.setdefault('m',torch.FloatTensor(x.size()).zero_().cuda(2))\n",
    "        config.setdefault('v',torch.FloatTensor(x.size()).zero_().cuda(2))\n",
    "        config.setdefault('t',0)\n",
    "    \n",
    "    next_x = None\n",
    "    config['t'] += 1\n",
    "    x.cuda(2)\n",
    "    dx.cuda(2)\n",
    "    config['m'] = config['beta1'] * config['m'] + (1 - config['beta1']) * dx\n",
    "    config['v'] = config['beta2'] * config['v'] + (1 - config['beta2']) * dx**2\n",
    "    mb = config['m'] / (1 - config['beta1'] ** config['t'])\n",
    "    vb = config['v'] / (1 - config['beta2'] ** config['t'])\n",
    "    next_x = x - config['learning_rate'] * mb / (np.sqrt(vb) + config['epsilon'])\n",
    "    return next_x, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd_momentum(w, dw, config = None):\n",
    "\n",
    "    if config is None: \n",
    "        config = {}\n",
    "        config.setdefault('learning_rate', 1e-2)\n",
    "        config.setdefault('momentum', 0.9)\n",
    "\n",
    "    v = config.get('velocity', torch.FloatTensor(w.size()).zero_().cuda(3))\n",
    "    next_w = None\n",
    "\n",
    "    v = config['momentum'] * v - config['learning_rate'] * dw\n",
    "    next_w = w + v\n",
    "    config['velocity'] = v\n",
    "\n",
    "    return next_w, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train_matrix_pred1-21.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d8d82a796ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_matrix_pred1-21.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmatrix_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_matrix_pred1-21.pkl'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatrix_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train_matrix_pred1-21.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "input1 = open('train_matrix_pred1-21.pkl', 'rb')\n",
    "matrix_pred = pkl.load(input1)\n",
    "output1 = open('train_matrix_pred1-21.pkl', 'wb')\n",
    "pkl.dump(matrix_pred, output1, protocol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
