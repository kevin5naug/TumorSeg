{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.init as ini\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        self.first_layer_down_conv1 = nn.Conv3d(4, 8, 3, padding = 1)\n",
    "        self.first_layer_down_bn1 = nn.BatchNorm3d(8)\n",
    "        self.first_layer_down_pre1 = nn.PReLU()\n",
    "        self.second_layer_down_conv1 = nn.Conv3d(8, 16, 3, padding = 1, stride = 2)\n",
    "        self.second_layer_down_bn1 = nn.BatchNorm3d(16)\n",
    "        self.second_layer_down_pre1 = nn.PReLU()\n",
    "        self.second_layer_down_conv2 = nn.Conv3d(16, 16, 3, padding = 1)\n",
    "        self.second_layer_down_bn2 = nn.BatchNorm3d(16)\n",
    "        self.second_layer_down_pre2 = nn.PReLU()\n",
    "        self.third_layer_down_conv1 = nn.Conv3d(16, 32, 3, padding = 1, stride = 2)\n",
    "        self.third_layer_down_bn1 = nn.BatchNorm3d(32)\n",
    "        self.third_layer_down_pre1 = nn.PReLU()\n",
    "        self.third_layer_down_conv2 = nn.Conv3d(32, 32, 3, padding = 1)\n",
    "        self.third_layer_down_bn2 = nn.BatchNorm3d(32)\n",
    "        self.third_layer_down_pre2 = nn.PReLU()\n",
    "        self.fourth_layer_down_conv1 = nn.Conv3d(32, 64, 3, padding = 1, stride = 2)\n",
    "        self.fourth_layer_down_bn1 = nn.BatchNorm3d(64)\n",
    "        self.fourth_layer_down_pre1 = nn.PReLU()\n",
    "        self.fourth_layer_down_conv2 = nn.Conv3d(64, 64, 3, padding = 1)\n",
    "        self.fourth_layer_up_conv1 = nn.Conv3d(64, 64, 1)\n",
    "        self.fourth_layer_up_bn1 = nn.BatchNorm3d(64)\n",
    "        self.fourth_layer_up_pre1 = nn.PReLU()\n",
    "        self.fourth_layer_up_deconv = nn.ConvTranspose3d(64, 32, 3, padding = 1, output_padding = 1, stride = 2)\n",
    "        self.fourth_layer_up_bn2 = nn.BatchNorm3d(32)\n",
    "        self.fourth_layer_up_pre2 = nn.PReLU()\n",
    "        self.third_layer_up_conv1 = nn.Conv3d(64, 64, 3, padding = 1)\n",
    "        self.third_layer_up_bn1 = nn.BatchNorm3d(64)\n",
    "        self.third_layer_up_pre1 = nn.PReLU()\n",
    "        self.third_layer_up_conv2 = nn.Conv3d(64, 32, 1)\n",
    "        self.third_layer_up_bn2 = nn.BatchNorm3d(32)\n",
    "        self.third_layer_up_pre2 = nn.PReLU()\n",
    "        self.third_layer_up_deconv = nn.ConvTranspose3d(32, 16, 3, padding = 1, output_padding = 1, stride = 2)\n",
    "        self.third_layer_up_bn3 = nn.BatchNorm3d(16)\n",
    "        self.third_layer_up_pre3 = nn.PReLU()\n",
    "        self.second_layer_up_conv1 = nn.Conv3d(32, 32, 3, padding = 1)\n",
    "        self.second_layer_up_bn1 = nn.BatchNorm3d(32)\n",
    "        self.second_layer_up_pre1 = nn.PReLU()\n",
    "        self.second_layer_up_conv2 = nn.Conv3d(32, 16, 1)\n",
    "        self.second_layer_up_bn2 = nn.BatchNorm3d(16)\n",
    "        self.second_layer_up_pre2 = nn.PReLU()\n",
    "        self.second_layer_up_deconv = nn.ConvTranspose3d(16, 8, 3, padding = 1, output_padding = 1, stride = 2)\n",
    "        self.second_layer_up_bn3 = nn.BatchNorm3d(8)\n",
    "        self.second_layer_up_pre3 = nn.PReLU()\n",
    "        self.first_layer_up_conv1 = nn.Conv3d(16, 16, 3, padding = 1)\n",
    "        self.first_layer_up_bn1 = nn.BatchNorm3d(16)\n",
    "        self.first_layer_up_pre1 = nn.PReLU()\n",
    "        self.third_seg = nn.Conv3d(64, 5, 1)\n",
    "        self.second_seg = nn.Conv3d(32, 5, 1)\n",
    "        self.first_seg = nn.Conv3d(16, 5, 1)\n",
    "        self.upsample_layer = nn.Upsample(scale_factor = 2, mode = 'trilinear')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_layer_down_conv1(x)\n",
    "        x = self.first_layer_down_bn1(x)\n",
    "        x = self.first_layer_down_pre1(x)\n",
    "        first_layer_feature = x\n",
    "        \n",
    "        x = self.second_layer_down_conv1(x)\n",
    "        temp = x\n",
    "        x = self.second_layer_down_bn1(x)\n",
    "        x = self.second_layer_down_pre1(x)\n",
    "        x = self.second_layer_down_conv2(x)\n",
    "        x = torch.add(x, temp)\n",
    "        x = self.second_layer_down_bn2(x)\n",
    "        x = self.second_layer_down_pre2(x)\n",
    "        second_layer_feature = x\n",
    "        \n",
    "        x = self.third_layer_down_conv1(x)\n",
    "        temp = x\n",
    "        x = self.third_layer_down_bn1(x)\n",
    "        x = self.third_layer_down_pre1(x)\n",
    "        x = self.third_layer_down_conv2(x)\n",
    "        x = torch.add(x, temp)\n",
    "        x = self.third_layer_down_bn2(x)\n",
    "        x = self.third_layer_down_pre2(x)\n",
    "        third_layer_feature = x\n",
    "        \n",
    "        x = self.fourth_layer_down_conv1(x)\n",
    "        temp = x\n",
    "        x = self.fourth_layer_down_bn1(x)\n",
    "        x = self.fourth_layer_down_pre1(x)\n",
    "        x = self.fourth_layer_down_conv2(x)\n",
    "        x = torch.add(x, temp)\n",
    "        \n",
    "        x = self.fourth_layer_up_conv1(x)\n",
    "        x = self.fourth_layer_up_bn1(x)\n",
    "        x = self.fourth_layer_up_pre1(x)\n",
    "        x = self.fourth_layer_up_deconv(x)\n",
    "        x = self.fourth_layer_up_bn2(x)\n",
    "        x = self.fourth_layer_up_pre2(x)\n",
    "        \n",
    "        x = torch.cat((x, third_layer_feature), 1)\n",
    "        x = self.third_layer_up_conv1(x)\n",
    "        x = self.third_layer_up_bn1(x)\n",
    "        x = self.third_layer_up_pre1(x)\n",
    "        third_seg_map = self.third_seg(x)\n",
    "        x = self.third_layer_up_conv2(x)\n",
    "        x = self.third_layer_up_bn2(x)\n",
    "        x = self.third_layer_up_pre2(x)\n",
    "        x = self.third_layer_up_deconv(x)\n",
    "        x = self.third_layer_up_bn3(x)\n",
    "        x = self.third_layer_up_pre3(x)\n",
    "        \n",
    "        x = torch.cat((x, second_layer_feature), 1)\n",
    "        x = self.second_layer_up_conv1(x)\n",
    "        x = self.second_layer_up_bn1(x)\n",
    "        x = self.second_layer_up_pre1(x)\n",
    "        second_seg_map = self.second_seg(x)\n",
    "        x = self.second_layer_up_conv2(x)\n",
    "        x = self.second_layer_up_bn2(x)\n",
    "        x = self.second_layer_up_pre2(x)\n",
    "        x = self.second_layer_up_deconv(x)\n",
    "        x = self.second_layer_up_bn3(x)\n",
    "        x = self.second_layer_up_pre3(x)\n",
    "        \n",
    "        x = torch.cat((x, first_layer_feature), 1)\n",
    "        x = self.first_layer_up_conv1(x)\n",
    "        x = self.first_layer_up_bn1(x)\n",
    "        x = self.first_layer_up_pre1(x)\n",
    "        first_seg_map = self.first_seg(x)\n",
    "        \n",
    "        third_seg_map = self.upsample_layer(third_seg_map)\n",
    "        second_seg_map = torch.add(third_seg_map, second_seg_map)\n",
    "        second_seg_map = self.upsample_layer(second_seg_map)\n",
    "        x = torch.add(first_seg_map, second_seg_map)\n",
    "        return x\n",
    "        \n",
    "net = Unet()\n",
    "net.cuda(1)\n",
    "prev_time = time.clock()\n",
    "\n",
    "for param in net.parameters():\n",
    "    try:\n",
    "        nout = param.size()[0]\n",
    "        nin = param.size()[1]\n",
    "        ini.normal(param.data, mean = 0, std = 0.01)\n",
    "        param = param / ((2/(nin+nout))**0.5)\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File('Unet-training.h5')\n",
    "SAMPLE = [ \"LG/0001\", \"LG/0002\", \"LG/0004\", \"LG/0006\", \"LG/0008\", \"LG/0011\",\n",
    "          \"LG/0012\", \"LG/0013\", \"LG/0014\", \"LG/0015\", \"HG/0001\", \"HG/0002\",\n",
    "          \"HG/0003\", \"HG/0004\", \"HG/0005\", \"HG/0006\", \"HG/0007\", \"HG/0008\",\n",
    "          \"HG/0009\", \"HG/0010\", \"HG/0011\", \"HG/0012\", \"HG/0013\", \"HG/0014\",\n",
    "          \"HG/0015\", \"HG/0022\", \"HG/0024\", \"HG/0025\", \"HG/0026\"]\n",
    "\n",
    "def create_train_batch(img = 0):\n",
    "    case = SAMPLE[img]\n",
    "    key0 = case[:2]\n",
    "    key1 = case[3:]\n",
    "    _, X, Y, Z = f[key0][key1].shape\n",
    "    train_batch = [];\n",
    "    train_label = [];\n",
    "    x = random.randint(64, X-64)\n",
    "    y = random.randint(64, Y-64)\n",
    "    z = random.randint(48, Z-48)\n",
    "    train_batch.append(f[key0][key1][0:4,x-64:x+64,y-64:y+64,z-48:z+48])\n",
    "    train_label.append(f[key0][key1][4,x-64:x+64,y-64:y+64,z-48:z+48])\n",
    "    train_batch = np.array(train_batch)\n",
    "    train_label = np.array(train_label)\n",
    "    train_batch = torch.from_numpy(train_batch)\n",
    "    train_label = torch.from_numpy(train_label)\n",
    "    train_label = torch.Tensor.long(train_label)\n",
    "    return train_batch, train_label\n",
    "\n",
    "def create_val():\n",
    "    case = \"HG/0001\"\n",
    "    key0 = case[:2]\n",
    "    key1 = case[3:]\n",
    "    _, X, Y, Z = f[key0][key1].shape\n",
    "    val_batch = [];\n",
    "    val_label = [];\n",
    "    x = X//2\n",
    "    y = Y//2\n",
    "    z = Z//2\n",
    "    val_batch.append(f[key0][key1][0:4,x-64:x+64,y-64:y+64,z-48:z+48])\n",
    "    val_label.append(f[key0][key1][4,x-64:x+64,y-64:y+64,z-48:z+48])\n",
    "    val_batch = np.array(val_batch)\n",
    "    val_label = np.array(val_label)\n",
    "    val_batch = torch.from_numpy(val_batch)\n",
    "    val_label = torch.from_numpy(val_label)\n",
    "    val_label = torch.Tensor.long(val_label)\n",
    "    return val_batch, val_label\n",
    "\n",
    "val_x, val_y = create_val()\n",
    "val_x = Variable(val_x).cuda(1)\n",
    "val_y = val_y.view(-1)\n",
    "val_y = val_y.cuda(1)\n",
    "y_pred = net.forward(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet (\n",
       "  (first_layer_down_conv1): Conv3d(4, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (first_layer_down_bn1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (first_layer_down_pre1): PReLU (1)\n",
       "  (second_layer_down_conv1): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "  (second_layer_down_bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (second_layer_down_pre1): PReLU (1)\n",
       "  (second_layer_down_conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (second_layer_down_bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (second_layer_down_pre2): PReLU (1)\n",
       "  (third_layer_down_conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "  (third_layer_down_bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (third_layer_down_pre1): PReLU (1)\n",
       "  (third_layer_down_conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (third_layer_down_bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (third_layer_down_pre2): PReLU (1)\n",
       "  (fourth_layer_down_conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "  (fourth_layer_down_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (fourth_layer_down_pre1): PReLU (1)\n",
       "  (fourth_layer_down_conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (fourth_layer_up_conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (fourth_layer_up_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (fourth_layer_up_pre1): PReLU (1)\n",
       "  (fourth_layer_up_deconv): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "  (fourth_layer_up_bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (fourth_layer_up_pre2): PReLU (1)\n",
       "  (third_layer_up_conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (third_layer_up_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (third_layer_up_pre1): PReLU (1)\n",
       "  (third_layer_up_conv2): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (third_layer_up_bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (third_layer_up_pre2): PReLU (1)\n",
       "  (third_layer_up_deconv): ConvTranspose3d(32, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "  (third_layer_up_bn3): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (third_layer_up_pre3): PReLU (1)\n",
       "  (second_layer_up_conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (second_layer_up_bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (second_layer_up_pre1): PReLU (1)\n",
       "  (second_layer_up_conv2): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (second_layer_up_bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (second_layer_up_pre2): PReLU (1)\n",
       "  (second_layer_up_deconv): ConvTranspose3d(16, 8, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "  (second_layer_up_bn3): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (second_layer_up_pre3): PReLU (1)\n",
       "  (first_layer_up_conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (first_layer_up_bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (first_layer_up_pre1): PReLU (1)\n",
       "  (third_seg): Conv3d(64, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (second_seg): Conv3d(32, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (first_seg): Conv3d(16, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (upsample_layer): Upsample(scale_factor=2, mode=trilinear)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "net.load_state_dict(torch.load('unet49.txt'))\n",
    "net.cuda(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFQwFSQVDQVLBUJBU+H+uAD+WKMHmLQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6cec727e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c9c4dbfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_x, val_y = create_val()\n",
    "val_x = Variable(val_x).cuda(1)\n",
    "y_pred = net.forward(val_x)\n",
    "y_pred = y_pred.view(5,-1)\n",
    "_, y_pred = torch.max(y_pred, 0)\n",
    "y_pred = y_pred.view(128,128,96)\n",
    "array_image = y_pred.data.cpu().numpy()\n",
    "\n",
    "plt.imshow(array_image[:,:,40], cmap = 'gray')\n",
    "print('fuck3')\n",
    "plt.show()\n",
    "val_y = val_y.numpy()\n",
    "print(val_y.shape)\n",
    "plt.imshow(val_y[0,:,:,40], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 128, 128, 96]) \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "â‹® \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.cuda.LongTensor of size 1572864 (GPU 1)]\n",
      "\n",
      "torch.Size([1, 5, 128, 128, 96])\n"
     ]
    }
   ],
   "source": [
    "print(val_x.size(), val_y)\n",
    "print(y_pred.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.7351\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.03339385986328125\n",
      "time used:8.496\n",
      "Variable containing:\n",
      " 1.3312\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.03982416788736979\n",
      "time used:10.345\n",
      "Variable containing:\n",
      " 2.0159\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.6446940104166666\n",
      "time used:12.206\n",
      "Variable containing:\n",
      " 1.6200\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.6697667439778646\n",
      "time used:14.067\n",
      "Variable containing:\n",
      " 1.4280\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.6549530029296875\n",
      "time used:15.940\n",
      "Variable containing:\n",
      " 1.4396\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.6136436462402344\n",
      "time used:17.808\n",
      "Variable containing:\n",
      " 1.4731\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.6773509979248047\n",
      "time used:19.681\n",
      "Variable containing:\n",
      " 1.2379\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.7134634653727213\n",
      "time used:21.539\n",
      "Variable containing:\n",
      " 1.1796\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.7540187835693359\n",
      "time used:23.403\n",
      "Variable containing:\n",
      " 1.6961\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.7780640920003256\n",
      "time used:25.267\n",
      "Variable containing:\n",
      " 1.6702\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.7925345102945963\n",
      "time used:27.120\n",
      "Variable containing:\n",
      " 0.8892\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8056869506835938\n",
      "time used:28.972\n",
      "Variable containing:\n",
      " 1.0296\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8137213389078776\n",
      "time used:30.826\n",
      "Variable containing:\n",
      " 1.1871\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8196722666422526\n",
      "time used:32.681\n",
      "Variable containing:\n",
      " 1.1399\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8253752390543619\n",
      "time used:34.540\n",
      "Variable containing:\n",
      " 1.0222\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8337955474853516\n",
      "time used:36.393\n",
      "Variable containing:\n",
      " 0.8952\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8493817647298177\n",
      "time used:38.253\n",
      "Variable containing:\n",
      " 0.7918\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8617439270019531\n",
      "time used:40.113\n",
      "Variable containing:\n",
      " 1.1794\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8702360788981119\n",
      "time used:41.964\n",
      "Variable containing:\n",
      " 1.1721\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8774325052897135\n",
      "time used:43.825\n",
      "Variable containing:\n",
      " 0.7119\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8871568044026693\n",
      "time used:45.701\n",
      "Variable containing:\n",
      " 0.9507\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8957977294921875\n",
      "time used:47.573\n",
      "Variable containing:\n",
      " 0.9937\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8933442433675131\n",
      "time used:49.449\n",
      "Variable containing:\n",
      " 0.7696\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8914407094319662\n",
      "time used:51.326\n",
      "Variable containing:\n",
      " 0.9762\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8865737915039062\n",
      "time used:53.193\n",
      "Variable containing:\n",
      " 0.7990\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8836587270100912\n",
      "time used:55.070\n",
      "Variable containing:\n",
      " 0.5088\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8821690877278646\n",
      "time used:56.940\n",
      "Variable containing:\n",
      " 0.4618\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8838043212890625\n",
      "time used:58.816\n",
      "Variable containing:\n",
      " 0.5136\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8871453603108724\n",
      "time used:60.683\n",
      "Variable containing:\n",
      " 1.5100\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8911596934000651\n",
      "time used:62.560\n",
      "Variable containing:\n",
      " 0.6610\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8970680236816406\n",
      "time used:64.429\n",
      "Variable containing:\n",
      " 1.0906\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8996429443359375\n",
      "time used:66.298\n",
      "Variable containing:\n",
      " 0.4303\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9020570119222006\n",
      "time used:68.174\n",
      "Variable containing:\n",
      " 0.8688\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9019495646158854\n",
      "time used:70.043\n",
      "Variable containing:\n",
      " 0.7309\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9020977020263672\n",
      "time used:71.913\n",
      "Variable containing:\n",
      " 0.2853\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9037113189697266\n",
      "time used:73.781\n",
      "Variable containing:\n",
      " 0.8814\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9028778076171875\n",
      "time used:75.656\n",
      "Variable containing:\n",
      " 0.3130\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9035822550455729\n",
      "time used:77.526\n",
      "Variable containing:\n",
      " 1.1579\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9018910725911459\n",
      "time used:79.403\n",
      "Variable containing:\n",
      " 0.2556\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9023106892903646\n",
      "time used:81.271\n",
      "Variable containing:\n",
      " 0.5000\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9035154978434244\n",
      "time used:83.148\n",
      "Variable containing:\n",
      " 0.4873\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9044399261474609\n",
      "time used:85.025\n",
      "Variable containing:\n",
      " 0.2253\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9049606323242188\n",
      "time used:86.896\n",
      "Variable containing:\n",
      " 0.4468\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9059263865152994\n",
      "time used:88.773\n",
      "Variable containing:\n",
      " 0.7181\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9059950510660807\n",
      "time used:90.643\n",
      "Variable containing:\n",
      " 0.4577\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9064935048421224\n",
      "time used:92.512\n",
      "Variable containing:\n",
      " 0.7913\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9070110321044922\n",
      "time used:94.381\n",
      "Variable containing:\n",
      " 1.1584\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9084211985270182\n",
      "time used:96.258\n",
      "Variable containing:\n",
      " 0.2650\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9104455312093099\n",
      "time used:98.134\n",
      "Variable containing:\n",
      " 0.2157\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9112453460693359\n",
      "time used:100.003\n",
      "Variable containing:\n",
      " 0.6107\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9123032887776693\n",
      "time used:101.881\n",
      "Variable containing:\n",
      " 0.6871\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9151604970296224\n",
      "time used:103.750\n",
      "Variable containing:\n",
      " 0.3146\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9139785766601562\n",
      "time used:105.627\n",
      "Variable containing:\n",
      " 0.2975\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9082965850830078\n",
      "time used:107.504\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e3f489b70052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = net.cuda(1)\n",
    "w = torch.Tensor([0.04/4, 0.998/4, 0.976/4, 0.995/4, 0.994/4])\n",
    "w = w.cuda(1)\n",
    "num_epoch = 200;\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr = 5e-3, weight_decay = 5e-6)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.9)\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    random.shuffle(SAMPLE)\n",
    "    for j in range(len(SAMPLE)):\n",
    "        train_batch, val_batch = create_train_batch(j)\n",
    "        train_batch = Variable(train_batch).cuda(1)\n",
    "        val_batch = Variable(val_batch).cuda(1)\n",
    "        out = net.forward(train_batch)\n",
    "        out = torch.transpose(out, 0, 1)\n",
    "        out.contiguous()\n",
    "        out = out.view(5, -1)\n",
    "        out = torch.transpose(out, 0, 1)\n",
    "        out.contiguous()\n",
    "        val_batch = val_batch.view(-1)\n",
    "        criterion = nn.CrossEntropyLoss(weight = w)\n",
    "        loss = criterion(out, val_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "        optimizer.step()\n",
    "        y_pred = net.forward(val_x)\n",
    "        y_pred = y_pred.view(5, -1)\n",
    "        y_pred = torch.transpose(y_pred, 0, 1)\n",
    "        out.contiguous()\n",
    "        _, y_pred = torch.max(y_pred.data, 1)\n",
    "        correct = (y_pred == val_y).sum()\n",
    "        print('Validation accuracy:', float(correct) / 128 / 128 / 96)\n",
    "        print('time used:%.3f'% (time.clock() - prev_time))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"unet.txt\")\n",
    "print (\"successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
