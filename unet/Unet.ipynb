{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.nn.init as ini\n",
    "import h5py\n",
    "import random\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "        self.first_layer_down_conv1 = nn.Conv3d(4, 8, 3, padding = 1)\n",
    "        self.first_layer_down_bn1 = nn.BatchNorm3d(8)\n",
    "        self.first_layer_down_pre1 = nn.PReLU()\n",
    "        self.second_layer_down_conv1 = nn.Conv3d(8, 16, 3, padding = 1, stride = 2)\n",
    "        self.second_layer_down_bn1 = nn.BatchNorm3d(16)\n",
    "        self.second_layer_down_pre1 = nn.PReLU()\n",
    "        self.second_layer_down_conv2 = nn.Conv3d(16, 16, 3, padding = 1)\n",
    "        self.second_layer_down_bn2 = nn.BatchNorm3d(16)\n",
    "        self.second_layer_down_pre2 = nn.PReLU()\n",
    "        self.third_layer_down_conv1 = nn.Conv3d(16, 32, 3, padding = 1, stride = 2)\n",
    "        self.third_layer_down_bn1 = nn.BatchNorm3d(32)\n",
    "        self.third_layer_down_pre1 = nn.PReLU()\n",
    "        self.third_layer_down_conv2 = nn.Conv3d(32, 32, 3, padding = 1)\n",
    "        self.third_layer_down_bn2 = nn.BatchNorm3d(32)\n",
    "        self.third_layer_down_pre2 = nn.PReLU()\n",
    "        self.fourth_layer_down_conv1 = nn.Conv3d(32, 64, 3, padding = 1, stride = 2)\n",
    "        self.fourth_layer_down_bn1 = nn.BatchNorm3d(64)\n",
    "        self.fourth_layer_down_pre1 = nn.PReLU()\n",
    "        self.fourth_layer_down_conv2 = nn.Conv3d(64, 64, 3, padding = 1)\n",
    "        self.fourth_layer_up_conv1 = nn.Conv3d(64, 64, 1)\n",
    "        self.fourth_layer_up_bn1 = nn.BatchNorm3d(64)\n",
    "        self.fourth_layer_up_pre1 = nn.PReLU()\n",
    "        self.fourth_layer_up_deconv = nn.ConvTranspose3d(64, 32, 3, padding = 1, output_padding = 1, stride = 2)\n",
    "        self.fourth_layer_up_bn2 = nn.BatchNorm3d(32)\n",
    "        self.fourth_layer_up_pre2 = nn.PReLU()\n",
    "        self.third_layer_up_conv1 = nn.Conv3d(64, 64, 3, padding = 1)\n",
    "        self.third_layer_up_bn1 = nn.BatchNorm3d(64)\n",
    "        self.third_layer_up_pre1 = nn.PReLU()\n",
    "        self.third_layer_up_conv2 = nn.Conv3d(64, 32, 1)\n",
    "        self.third_layer_up_bn2 = nn.BatchNorm3d(32)\n",
    "        self.third_layer_up_pre2 = nn.PReLU()\n",
    "        self.third_layer_up_deconv = nn.ConvTranspose3d(32, 16, 3, padding = 1, output_padding = 1, stride = 2)\n",
    "        self.third_layer_up_bn3 = nn.BatchNorm3d(16)\n",
    "        self.third_layer_up_pre3 = nn.PReLU()\n",
    "        self.second_layer_up_conv1 = nn.Conv3d(32, 32, 3, padding = 1)\n",
    "        self.second_layer_up_bn1 = nn.BatchNorm3d(32)\n",
    "        self.second_layer_up_pre1 = nn.PReLU()\n",
    "        self.second_layer_up_conv2 = nn.Conv3d(32, 16, 1)\n",
    "        self.second_layer_up_bn2 = nn.BatchNorm3d(16)\n",
    "        self.second_layer_up_pre2 = nn.PReLU()\n",
    "        self.second_layer_up_deconv = nn.ConvTranspose3d(16, 8, 3, padding = 1, output_padding = 1, stride = 2)\n",
    "        self.second_layer_up_bn3 = nn.BatchNorm3d(8)\n",
    "        self.second_layer_up_pre3 = nn.PReLU()\n",
    "        self.first_layer_up_conv1 = nn.Conv3d(16, 16, 3, padding = 1)\n",
    "        self.first_layer_up_bn1 = nn.BatchNorm3d(16)\n",
    "        self.first_layer_up_pre1 = nn.PReLU()\n",
    "        self.third_seg = nn.Conv3d(64, 5, 1)\n",
    "        self.second_seg = nn.Conv3d(32, 5, 1)\n",
    "        self.first_seg = nn.Conv3d(16, 5, 1)\n",
    "        self.upsample_layer = nn.Upsample(scale_factor = 2, mode = 'trilinear')\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.first_layer_down_conv1(x)\n",
    "        x = self.first_layer_down_bn1(x)\n",
    "        x = self.first_layer_down_pre1(x)\n",
    "        first_layer_feature = x\n",
    "        \n",
    "        x = self.second_layer_down_conv1(x)\n",
    "        temp = x\n",
    "        x = self.second_layer_down_bn1(x)\n",
    "        x = self.second_layer_down_pre1(x)\n",
    "        x = self.second_layer_down_conv2(x)\n",
    "        x = torch.add(x, temp)\n",
    "        x = self.second_layer_down_bn2(x)\n",
    "        x = self.second_layer_down_pre2(x)\n",
    "        second_layer_feature = x\n",
    "        \n",
    "        x = self.third_layer_down_conv1(x)\n",
    "        temp = x\n",
    "        x = self.third_layer_down_bn1(x)\n",
    "        x = self.third_layer_down_pre1(x)\n",
    "        x = self.third_layer_down_conv2(x)\n",
    "        x = torch.add(x, temp)\n",
    "        x = self.third_layer_down_bn2(x)\n",
    "        x = self.third_layer_down_pre2(x)\n",
    "        third_layer_feature = x\n",
    "        \n",
    "        x = self.fourth_layer_down_conv1(x)\n",
    "        temp = x\n",
    "        x = self.fourth_layer_down_bn1(x)\n",
    "        x = self.fourth_layer_down_pre1(x)\n",
    "        x = self.fourth_layer_down_conv2(x)\n",
    "        x = torch.add(x, temp)\n",
    "        \n",
    "        x = self.fourth_layer_up_conv1(x)\n",
    "        x = self.fourth_layer_up_bn1(x)\n",
    "        x = self.fourth_layer_up_pre1(x)\n",
    "        x = self.fourth_layer_up_deconv(x)\n",
    "        x = self.fourth_layer_up_bn2(x)\n",
    "        x = self.fourth_layer_up_pre2(x)\n",
    "        \n",
    "        x = torch.cat((x, third_layer_feature), 1)\n",
    "        x = self.third_layer_up_conv1(x)\n",
    "        x = self.third_layer_up_bn1(x)\n",
    "        x = self.third_layer_up_pre1(x)\n",
    "        third_seg_map = self.third_seg(x)\n",
    "        x = self.third_layer_up_conv2(x)\n",
    "        x = self.third_layer_up_bn2(x)\n",
    "        x = self.third_layer_up_pre2(x)\n",
    "        x = self.third_layer_up_deconv(x)\n",
    "        x = self.third_layer_up_bn3(x)\n",
    "        x = self.third_layer_up_pre3(x)\n",
    "        \n",
    "        x = torch.cat((x, second_layer_feature), 1)\n",
    "        x = self.second_layer_up_conv1(x)\n",
    "        x = self.second_layer_up_bn1(x)\n",
    "        x = self.second_layer_up_pre1(x)\n",
    "        second_seg_map = self.second_seg(x)\n",
    "        x = self.second_layer_up_conv2(x)\n",
    "        x = self.second_layer_up_bn2(x)\n",
    "        x = self.second_layer_up_pre2(x)\n",
    "        x = self.second_layer_up_deconv(x)\n",
    "        x = self.second_layer_up_bn3(x)\n",
    "        x = self.second_layer_up_pre3(x)\n",
    "        \n",
    "        x = torch.cat((x, first_layer_feature), 1)\n",
    "        x = self.first_layer_up_conv1(x)\n",
    "        x = self.first_layer_up_bn1(x)\n",
    "        x = self.first_layer_up_pre1(x)\n",
    "        first_seg_map = self.first_seg(x)\n",
    "        \n",
    "        third_seg_map = self.upsample_layer(third_seg_map)\n",
    "        second_seg_map = torch.add(third_seg_map, second_seg_map)\n",
    "        second_seg_map = self.upsample_layer(second_seg_map)\n",
    "        x = torch.add(first_seg_map, second_seg_map)\n",
    "        return x\n",
    "        \n",
    "net = Unet()\n",
    "net.cuda(1)\n",
    "prev_time = time.clock()\n",
    "\n",
    "for param in net.parameters():\n",
    "    try:\n",
    "        nout = param.size()[0]\n",
    "        nin = param.size()[1]\n",
    "        ini.normal(param.data, mean = 0, std = 0.01)\n",
    "        param = param / ((2/(nin+nout))**0.5)\n",
    "    except:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = h5py.File('Unet-training.h5')\n",
    "SAMPLE = [ \"LG/0001\", \"LG/0002\", \"LG/0004\", \"LG/0006\", \"LG/0008\", \"LG/0011\",\n",
    "          \"LG/0012\", \"LG/0013\", \"LG/0014\", \"LG/0015\", \"HG/0001\", \"HG/0002\",\n",
    "          \"HG/0003\", \"HG/0004\", \"HG/0005\", \"HG/0006\", \"HG/0007\", \"HG/0008\",\n",
    "          \"HG/0009\", \"HG/0010\", \"HG/0011\", \"HG/0012\", \"HG/0013\", \"HG/0014\",\n",
    "          \"HG/0015\", \"HG/0022\", \"HG/0024\", \"HG/0025\", \"HG/0026\"]\n",
    "\n",
    "def create_train_batch(img = 0):\n",
    "    case = SAMPLE[img]\n",
    "    key0 = case[:2]\n",
    "    key1 = case[3:]\n",
    "    _, X, Y, Z = f[key0][key1].shape\n",
    "    train_batch = [];\n",
    "    train_label = [];\n",
    "    x = random.randint(64, X-64)\n",
    "    y = random.randint(64, Y-64)\n",
    "    z = random.randint(48, Z-48)\n",
    "    train_batch.append(f[key0][key1][0:4,x-64:x+64,y-64:y+64,z-48:z+48])\n",
    "    train_label.append(f[key0][key1][4,x-64:x+64,y-64:y+64,z-48:z+48])\n",
    "    train_batch = np.array(train_batch)\n",
    "    train_label = np.array(train_label)\n",
    "    train_batch = torch.from_numpy(train_batch)\n",
    "    train_label = torch.from_numpy(train_label)\n",
    "    train_label = torch.Tensor.long(train_label)\n",
    "    return train_batch, train_label\n",
    "\n",
    "def create_val():\n",
    "    case = \"HG/0001\"\n",
    "    key0 = case[:2]\n",
    "    key1 = case[3:]\n",
    "    _, X, Y, Z = f[key0][key1].shape\n",
    "    val_batch = [];\n",
    "    val_label = [];\n",
    "    x = X//2\n",
    "    y = Y//2\n",
    "    z = Z//2\n",
    "    val_batch.append(f[key0][key1][0:4,x-64:x+64,y-64:y+64,z-48:z+48])\n",
    "    val_label.append(f[key0][key1][4,x-64:x+64,y-64:y+64,z-48:z+48])\n",
    "    val_batch = np.array(val_batch)\n",
    "    val_label = np.array(val_label)\n",
    "    val_batch = torch.from_numpy(val_batch)\n",
    "    val_label = torch.from_numpy(val_label)\n",
    "    val_label = torch.Tensor.long(val_label)\n",
    "    return val_batch, val_label\n",
    "\n",
    "val_x, val_y = create_val()\n",
    "val_x = Variable(val_x).cuda(1)\n",
    "val_y = val_y.view(-1)\n",
    "val_y = val_y.cuda(1)\n",
    "y_pred = net.forward(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet (\n",
       "  (first_layer_down_conv1): Conv3d(4, 8, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (first_layer_down_bn1): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (first_layer_down_pre1): PReLU (1)\n",
       "  (second_layer_down_conv1): Conv3d(8, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "  (second_layer_down_bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (second_layer_down_pre1): PReLU (1)\n",
       "  (second_layer_down_conv2): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (second_layer_down_bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (second_layer_down_pre2): PReLU (1)\n",
       "  (third_layer_down_conv1): Conv3d(16, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "  (third_layer_down_bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (third_layer_down_pre1): PReLU (1)\n",
       "  (third_layer_down_conv2): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (third_layer_down_bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (third_layer_down_pre2): PReLU (1)\n",
       "  (fourth_layer_down_conv1): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "  (fourth_layer_down_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (fourth_layer_down_pre1): PReLU (1)\n",
       "  (fourth_layer_down_conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (fourth_layer_up_conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (fourth_layer_up_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (fourth_layer_up_pre1): PReLU (1)\n",
       "  (fourth_layer_up_deconv): ConvTranspose3d(64, 32, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "  (fourth_layer_up_bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (fourth_layer_up_pre2): PReLU (1)\n",
       "  (third_layer_up_conv1): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (third_layer_up_bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (third_layer_up_pre1): PReLU (1)\n",
       "  (third_layer_up_conv2): Conv3d(64, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (third_layer_up_bn2): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (third_layer_up_pre2): PReLU (1)\n",
       "  (third_layer_up_deconv): ConvTranspose3d(32, 16, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "  (third_layer_up_bn3): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (third_layer_up_pre3): PReLU (1)\n",
       "  (second_layer_up_conv1): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (second_layer_up_bn1): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (second_layer_up_pre1): PReLU (1)\n",
       "  (second_layer_up_conv2): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (second_layer_up_bn2): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (second_layer_up_pre2): PReLU (1)\n",
       "  (second_layer_up_deconv): ConvTranspose3d(16, 8, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), output_padding=(1, 1, 1))\n",
       "  (second_layer_up_bn3): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (second_layer_up_pre3): PReLU (1)\n",
       "  (first_layer_up_conv1): Conv3d(16, 16, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "  (first_layer_up_bn1): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (first_layer_up_pre1): PReLU (1)\n",
       "  (third_seg): Conv3d(64, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (second_seg): Conv3d(32, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (first_seg): Conv3d(16, 5, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (upsample_layer): Upsample(scale_factor=2, mode=trilinear)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "net.load_state_dict(torch.load('unet39.txt'))\n",
    "net.cuda(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fuck3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noSCpYShIahgKkhqGgqSGoSCpYShIavw/VQFWZnBAyVUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2617d00b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 128, 96)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQUAAAD8CAYAAAB+fLH0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8+SGjfMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd2614ddeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_x, val_y = create_val()\n",
    "val_x = Variable(val_x).cuda(1)\n",
    "y_pred = net.forward(val_x)\n",
    "y_pred = y_pred.view(5,-1)\n",
    "_, y_pred = torch.max(y_pred, 0)\n",
    "y_pred = y_pred.view(128,128,96)\n",
    "array_image = y_pred.data.cpu().numpy()\n",
    "\n",
    "plt.imshow(array_image[:,:,60], cmap = 'gray')\n",
    "plt.show()\n",
    "val_y = val_y.numpy()\n",
    "print(val_y.shape)\n",
    "plt.imshow(val_y[0,:,:,60], cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 128, 128, 96]) \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "⋮ \n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.cuda.LongTensor of size 1572864 (GPU 1)]\n",
      "\n",
      "torch.Size([1, 5, 128, 128, 96])\n"
     ]
    }
   ],
   "source": [
    "print(val_x.size(), val_y)\n",
    "print(y_pred.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1.7351\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.03339385986328125\n",
      "time used:8.496\n",
      "Variable containing:\n",
      " 1.3312\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.03982416788736979\n",
      "time used:10.345\n",
      "Variable containing:\n",
      " 2.0159\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.6446940104166666\n",
      "time used:12.206\n",
      "Variable containing:\n",
      " 1.6200\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.6697667439778646\n",
      "time used:14.067\n",
      "Variable containing:\n",
      " 1.4280\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.6549530029296875\n",
      "time used:15.940\n",
      "Variable containing:\n",
      " 1.4396\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.6136436462402344\n",
      "time used:17.808\n",
      "Variable containing:\n",
      " 1.4731\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.6773509979248047\n",
      "time used:19.681\n",
      "Variable containing:\n",
      " 1.2379\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.7134634653727213\n",
      "time used:21.539\n",
      "Variable containing:\n",
      " 1.1796\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.7540187835693359\n",
      "time used:23.403\n",
      "Variable containing:\n",
      " 1.6961\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.7780640920003256\n",
      "time used:25.267\n",
      "Variable containing:\n",
      " 1.6702\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.7925345102945963\n",
      "time used:27.120\n",
      "Variable containing:\n",
      " 0.8892\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8056869506835938\n",
      "time used:28.972\n",
      "Variable containing:\n",
      " 1.0296\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8137213389078776\n",
      "time used:30.826\n",
      "Variable containing:\n",
      " 1.1871\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8196722666422526\n",
      "time used:32.681\n",
      "Variable containing:\n",
      " 1.1399\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8253752390543619\n",
      "time used:34.540\n",
      "Variable containing:\n",
      " 1.0222\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8337955474853516\n",
      "time used:36.393\n",
      "Variable containing:\n",
      " 0.8952\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8493817647298177\n",
      "time used:38.253\n",
      "Variable containing:\n",
      " 0.7918\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8617439270019531\n",
      "time used:40.113\n",
      "Variable containing:\n",
      " 1.1794\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8702360788981119\n",
      "time used:41.964\n",
      "Variable containing:\n",
      " 1.1721\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8774325052897135\n",
      "time used:43.825\n",
      "Variable containing:\n",
      " 0.7119\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8871568044026693\n",
      "time used:45.701\n",
      "Variable containing:\n",
      " 0.9507\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8957977294921875\n",
      "time used:47.573\n",
      "Variable containing:\n",
      " 0.9937\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8933442433675131\n",
      "time used:49.449\n",
      "Variable containing:\n",
      " 0.7696\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8914407094319662\n",
      "time used:51.326\n",
      "Variable containing:\n",
      " 0.9762\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8865737915039062\n",
      "time used:53.193\n",
      "Variable containing:\n",
      " 0.7990\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8836587270100912\n",
      "time used:55.070\n",
      "Variable containing:\n",
      " 0.5088\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8821690877278646\n",
      "time used:56.940\n",
      "Variable containing:\n",
      " 0.4618\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8838043212890625\n",
      "time used:58.816\n",
      "Variable containing:\n",
      " 0.5136\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8871453603108724\n",
      "time used:60.683\n",
      "Variable containing:\n",
      " 1.5100\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8911596934000651\n",
      "time used:62.560\n",
      "Variable containing:\n",
      " 0.6610\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8970680236816406\n",
      "time used:64.429\n",
      "Variable containing:\n",
      " 1.0906\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.8996429443359375\n",
      "time used:66.298\n",
      "Variable containing:\n",
      " 0.4303\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9020570119222006\n",
      "time used:68.174\n",
      "Variable containing:\n",
      " 0.8688\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9019495646158854\n",
      "time used:70.043\n",
      "Variable containing:\n",
      " 0.7309\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9020977020263672\n",
      "time used:71.913\n",
      "Variable containing:\n",
      " 0.2853\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9037113189697266\n",
      "time used:73.781\n",
      "Variable containing:\n",
      " 0.8814\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9028778076171875\n",
      "time used:75.656\n",
      "Variable containing:\n",
      " 0.3130\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9035822550455729\n",
      "time used:77.526\n",
      "Variable containing:\n",
      " 1.1579\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9018910725911459\n",
      "time used:79.403\n",
      "Variable containing:\n",
      " 0.2556\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9023106892903646\n",
      "time used:81.271\n",
      "Variable containing:\n",
      " 0.5000\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9035154978434244\n",
      "time used:83.148\n",
      "Variable containing:\n",
      " 0.4873\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9044399261474609\n",
      "time used:85.025\n",
      "Variable containing:\n",
      " 0.2253\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9049606323242188\n",
      "time used:86.896\n",
      "Variable containing:\n",
      " 0.4468\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9059263865152994\n",
      "time used:88.773\n",
      "Variable containing:\n",
      " 0.7181\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9059950510660807\n",
      "time used:90.643\n",
      "Variable containing:\n",
      " 0.4577\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9064935048421224\n",
      "time used:92.512\n",
      "Variable containing:\n",
      " 0.7913\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9070110321044922\n",
      "time used:94.381\n",
      "Variable containing:\n",
      " 1.1584\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9084211985270182\n",
      "time used:96.258\n",
      "Variable containing:\n",
      " 0.2650\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9104455312093099\n",
      "time used:98.134\n",
      "Variable containing:\n",
      " 0.2157\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9112453460693359\n",
      "time used:100.003\n",
      "Variable containing:\n",
      " 0.6107\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9123032887776693\n",
      "time used:101.881\n",
      "Variable containing:\n",
      " 0.6871\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9151604970296224\n",
      "time used:103.750\n",
      "Variable containing:\n",
      " 0.3146\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9139785766601562\n",
      "time used:105.627\n",
      "Variable containing:\n",
      " 0.2975\n",
      "[torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
      "\n",
      "Validation accuracy: 0.9082965850830078\n",
      "time used:107.504\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e3f489b70052>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \"\"\"\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/yiqin/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "net = net.cuda(1)\n",
    "w = torch.Tensor([0.04/4, 0.998/4, 0.976/4, 0.995/4, 0.994/4])\n",
    "w = w.cuda(1)\n",
    "num_epoch = 200;\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr = 5e-3, weight_decay = 5e-6)\n",
    "scheduler = StepLR(optimizer, step_size=5, gamma=0.9)\n",
    "\n",
    "for i in range(num_epoch):\n",
    "    random.shuffle(SAMPLE)\n",
    "    for j in range(len(SAMPLE)):\n",
    "        train_batch, val_batch = create_train_batch(j)\n",
    "        train_batch = Variable(train_batch).cuda(1)\n",
    "        val_batch = Variable(val_batch).cuda(1)\n",
    "        out = net.forward(train_batch)\n",
    "        out = torch.transpose(out, 0, 1)\n",
    "        out.contiguous()\n",
    "        out = out.view(5, -1)\n",
    "        out = torch.transpose(out, 0, 1)\n",
    "        out.contiguous()\n",
    "        val_batch = val_batch.view(-1)\n",
    "        criterion = nn.CrossEntropyLoss(weight = w)\n",
    "        loss = criterion(out, val_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        print(loss)\n",
    "        \n",
    "        optimizer.step()\n",
    "        y_pred = net.forward(val_x)\n",
    "        y_pred = y_pred.view(5, -1)\n",
    "        y_pred = torch.transpose(y_pred, 0, 1)\n",
    "        out.contiguous()\n",
    "        _, y_pred = torch.max(y_pred.data, 1)\n",
    "        correct = (y_pred == val_y).sum()\n",
    "        print('Validation accuracy:', float(correct) / 128 / 128 / 96)\n",
    "        print('time used:%.3f'% (time.clock() - prev_time))\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"unet.txt\")\n",
    "print (\"successfully saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
